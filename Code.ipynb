{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riDZcCw5R6jw"
      },
      "source": [
        "# Assignment 3\n",
        "## Group 33\n",
        "\n",
        "### Option 2: Tomato Leaf Diseases Detection (100% overall Mark)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "In this assignment, we address the problem of automatically detecting and localising various tomato leaf diseases using computer vision techniques. Manual inspection of tomato leaves for disease symptoms is time-consuming, error-prone, and not scalable in large-scale agricultural settings. Recent advances in deep learning–based object detection have made it possible to accurately and efficiently identify diseased regions, even when lesions are small or poorly contrasted against the background.\n",
        "\n",
        "**Project Choice:**  \n",
        "After reviewing the two project options provided for ELEC5304 Assignment 3, we have chosen **Option 2: Tomato Leaf Diseases Detection**. The goal of Option 2 is to build a custom, lightweight object detector from scratch rather than relying on off‐the‐shelf models and to achieve the following minimum performance targets on the test set:\n",
        "\n",
        "- **Box Precision ≥ 0.75** (IoU ≥ 0.50)  \n",
        "- **mAP@50 ≥ 0.75**  \n",
        "- One additional metric of our choice (in this notebook, we will use F1@0.50)\n",
        "\n",
        "Furthermore, Option 2 requires an enhancement phase in which we incorporate a Fourier‐based regularisation loss to encourage the network to capture high‐frequency texture patterns (e.g., small lesion edges). The Fourier loss should help improve the localisation and recognition of subtle disease spots that may be difficult to detect in purely spatial domains.\n"
      ],
      "metadata": {
        "id": "PE-sgXAiT4JW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym-2OwOzR6jx"
      },
      "source": [
        "### 1.1 Environment & Dependency Installation\n",
        "\n",
        "To begin, we install the necessary Python packages for our YOLOv8-based detection pipeline, image I/O, progress bars, and fast data augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-05-26T06:20:36.343278Z",
          "iopub.status.busy": "2025-05-26T06:20:36.342934Z",
          "iopub.status.idle": "2025-05-26T06:22:23.526253Z",
          "shell.execute_reply": "2025-05-26T06:22:23.525452Z",
          "shell.execute_reply.started": "2025-05-26T06:20:36.343253Z"
        },
        "id": "Dzf8FywwkYZt",
        "outputId": "273d52cb-eed3-4394-ca1e-b583cd04ad88",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.145-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\n",
            "Downloading ultralytics-8.3.145-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mmm00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
            "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
            "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
            "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.145 ultralytics-thop-2.0.14\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.3.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.5)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-2.0.7-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.4)\n",
            "Collecting albucore==0.0.24 (from albumentations)\n",
            "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.2.1)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.3.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\n",
            "Downloading albumentations-2.0.7-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: albucore, albumentations\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.23\n",
            "    Uninstalling albucore-0.0.23:\n",
            "      Successfully uninstalled albucore-0.0.23\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.5\n",
            "    Uninstalling albumentations-2.0.5:\n",
            "      Successfully uninstalled albumentations-2.0.5\n",
            "Successfully installed albucore-0.0.24 albumentations-2.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics          # Installs the Ultralytics YOLOv8 library for object detection\n",
        "!pip install opencv-python        # Installs OpenCV for loading/manipulating images\n",
        "!pip install tqdm                 # Installs tqdm to display progress bars during loops\n",
        "!pip install -U albumentations    # Installs Albumentations for fast, flexible image augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yURDsRQCR6jy"
      },
      "source": [
        "### 1.2 Imports & Dependencies\n",
        "\n",
        "We import all required Python modules and libraries for data handling, model training, and augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:23:46.660449Z",
          "iopub.status.busy": "2025-05-26T06:23:46.660123Z",
          "iopub.status.idle": "2025-05-26T06:23:49.662148Z",
          "shell.execute_reply": "2025-05-26T06:23:49.661355Z",
          "shell.execute_reply.started": "2025-05-26T06:23:46.660427Z"
        },
        "id": "2r05WMp6kYZu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os                                               # For interacting with the operating system (file paths, directories)\n",
        "from ultralytics import YOLO                            # High-level API for YOLOv8 (model definition, training, evaluation)\n",
        "import yaml                                             # For reading/writing YAML configuration files\n",
        "import shutil                                           # For file and directory operations (copy/move/delete)\n",
        "from sklearn.model_selection import train_test_split    # For splitting our dataset into training and validation subsets\n",
        "import cv2                                              # OpenCV for image operations (reading, color conversion)\n",
        "from ultralytics.data.dataset import YOLODataset        # Base dataset class used internally by YOLOv8\n",
        "from PIL import Image                                   # Python Imaging Library (alternative image I/O)\n",
        "import numpy as np                                      # Fundamental package for numerical computations\n",
        "from ultralytics.data.augment import LetterBox          # YOLOv8’s built-in letterbox/padding utility\n",
        "import torch                                            # PyTorch for tensor operations and model customization\n",
        "import albumentations as A                              # Albumentations library for fast, flexible image augmentation\n",
        "from albumentations.pytorch import ToTensorV2           # Converts augmented images to PyTorch tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training and Test Dataset Description\n",
        "\n",
        "The dataset for Option 2 has been divided into two parts:\n",
        "\n",
        "- **Training Set**  \n",
        "  - Contains all annotated images used to train our detector.  \n",
        "  - Each sample consists of:\n",
        "    1. An RGB image of a tomato leaf (JPEG/PNG format).  \n",
        "    2. A corresponding `.txt` file with one or more lines of the form  \n",
        "       ```\n",
        "       <class_id> <x_center_norm> <y_center_norm> <w_norm> <h_norm>\n",
        "       ```  \n",
        "       Where:\n",
        "       - `<class_id>` ∈ {0, 1, 2, 3, 4, 5, 6} represents one of seven categories (six disease types + Healthy).  \n",
        "       - `x_center_norm` and `y_center_norm` are the normalised (0→1) centre coordinates of the bounding box.  \n",
        "       - `w_norm` and `h_norm` are the normalised width and height of the box.  \n",
        "  - Overall, there are approximately 600 images in the training set, covering all seven classes (including “Healthy” leaves).  \n",
        "  - Images vary in resolution but will be uniformly resized and letter-boxed to 640 × 640 before being fed into the network.\n",
        "\n",
        "- **Test Set**  \n",
        "  - Contains unseen images and annotations reserved for final evaluation of Box Precision, mAP@50, and F1@0.50.  \n",
        "  - Each image in the test folder also has a `.txt` file with one or more normalised bounding box annotations, following the same format as the training set.  \n",
        "  - The test set is used to measure performance metrics only after training is complete (no gradient updates are performed on test samples).\n",
        "\n",
        "In both sets, class 2 corresponds to “Healthy” leaves (no visible lesions), while classes 0–1 and 3–6 represent six different tomato‐leaf diseases:\n",
        "0. Bacterial Spot  \n",
        "1. Early Blight  \n",
        "2. Healthy  \n",
        "3. Late Blight  \n",
        "4. Leaf Mold  \n",
        "5. Target Spot  \n",
        "6. Black Spot  \n",
        "\n",
        "The images exhibit variability in lighting, background clutter, and lesion size, posing a realistic challenge for lesion localisation. Before training, we will load each image, convert any grayscale inputs to RGB, and verify that its annotation file contains at least one valid bounding box (classes 0–6). Any images without annotations (empty `.txt` files) have been removed from both training and test folders to ensure that the model only learns from correctly labelled samples."
      ],
      "metadata": {
        "id": "B52StL-2VN3X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Qz3Xu3R6j3"
      },
      "source": [
        "### 2.1 Clean Slate & Dataset Folder Setup\n",
        "\n",
        "This cell removes any previous training outputs and recreates a fresh directory structure for our tomato‐leaf dataset. It then copies the raw images and labels from the Kaggle input into the newly created folders.\n",
        "\n",
        "> **Note:** All experiments in this notebook were conducted on Kaggle’s free GPU environment, as we found Google Colab to be too slow for our workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:23:53.949857Z",
          "iopub.status.busy": "2025-05-26T06:23:53.949420Z",
          "iopub.status.idle": "2025-05-26T06:23:56.604327Z",
          "shell.execute_reply": "2025-05-26T06:23:56.603182Z",
          "shell.execute_reply.started": "2025-05-26T06:23:53.949828Z"
        },
        "id": "0cKr2kDPkYZv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Remove any past training runs or leftover dataset folders to start fresh\n",
        "!rm -rf /kaggle/working/runs\n",
        "!rm -rf /kaggle/working/tomato_leaf_dataset\n",
        "\n",
        "# Re-create the train/test folder hierarchy under `/kaggle/working`\n",
        "!mkdir -p /kaggle/working/tomato_leaf_dataset/train/labels\n",
        "!mkdir -p /kaggle/working/tomato_leaf_dataset/train/images\n",
        "!mkdir -p /kaggle/working/tomato_leaf_dataset/test/labels\n",
        "!mkdir -p /kaggle/working/tomato_leaf_dataset/test/images\n",
        "\n",
        "# Copy the Kaggle “test” subset: images and corresponding label files\n",
        "!cp /kaggle/input/leave-tomota-image/test/test/images/* \\\n",
        "      /kaggle/working/tomato_leaf_dataset/test/images/.\n",
        "!cp /kaggle/input/leave-tomota-image/test/test/labels/* \\\n",
        "      /kaggle/working/tomato_leaf_dataset/test/labels/.\n",
        "\n",
        "# Copy the Kaggle “train” subset: images and corresponding label files\n",
        "!cp /kaggle/input/leave-tomota-image/train/train/images/* \\\n",
        "      /kaggle/working/tomato_leaf_dataset/train/images/.\n",
        "!cp /kaggle/input/leave-tomota-image/train/train/labels/* \\\n",
        "      /kaggle/working/tomato_leaf_dataset/train/labels/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFq6D5neR6j3"
      },
      "source": [
        "### 2.2 Hyperparameters & Directory Paths\n",
        "\n",
        "In this cell, we define key hyperparameters that control image sizing, batch processing, and YOLO’s loss thresholds. We also set up the file paths for our train split directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:23:56.606247Z",
          "iopub.status.busy": "2025-05-26T06:23:56.605929Z",
          "iopub.status.idle": "2025-05-26T06:23:56.611112Z",
          "shell.execute_reply": "2025-05-26T06:23:56.610527Z",
          "shell.execute_reply.started": "2025-05-26T06:23:56.606215Z"
        },
        "id": "b77F6DCukYZv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Size to which every image will be letter-boxed (longer side = 640 px, then padded to 640×640)\n",
        "IMG_SIZE = 640\n",
        "\n",
        "# Batch size per GPU during training/validation\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# IoU threshold used for assigning positive/negative anchors during training (toy placeholder here)\n",
        "iou = 0.001\n",
        "\n",
        "# Confidence threshold used during training to filter low-confidence predictions (toy placeholder here)\n",
        "conf = 0.099\n",
        "\n",
        "# Multiplier for the box-regression loss term (gain applied to CIoU/GIoU loss)\n",
        "box = 1.0\n",
        "\n",
        "# Base paths for input (Kaggle-provided) and output (working directory)\n",
        "base_input_path  = \"/kaggle/input/leave-tomota-image\"\n",
        "base_output_path = \"/kaggle/working\"\n",
        "\n",
        "# Directories containing training labels and images (used later in cleaning and custom dataset)\n",
        "label_folder = f\"{base_output_path}/tomato_leaf_dataset/train/labels\"\n",
        "image_folder = f\"{base_output_path}/tomato_leaf_dataset/train/images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJgdgZdzR6j4"
      },
      "source": [
        "## 3 Data Preprocessing\n",
        "\n",
        "1. **Letterbox to 640×640:**  \n",
        "   - Each image is resized so its longer side = 640 pixels, then padded (black) on the shorter side to form a 640×640 square.  \n",
        "   - **Why?** Preserves aspect ratio so that small lesions are not distorted or squashed. YOLOv8 requires square inputs, and we choose 640 as a trade-off between resolution (small spot visibility) and GPU memory/speed.\n",
        "\n",
        "2. **Handling Grayscale & Missing Labels:**  \n",
        "   - Some raw training images were single-channel (grayscale). We detect these by checking `img.shape[2] == 1` and convert them to 3-channel by repeating the gray channel:  \n",
        "     ```python\n",
        "     if img.shape[2] == 1:\n",
        "         img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "     ```  \n",
        "   - We scan `train/labels` for 0-byte `.txt` files and delete those files plus their corresponding image (`.jpg` or `.png`). This prevents YOLO from crashing on images with no ground truths.\n",
        "\n",
        "3. **Pixel Normalization:**  \n",
        "   - After letterboxing, we normalize pixel values per channel using Albumentations’ `Normalize()` (subtract dataset mean, divide by dataset std). For example:  \n",
        "     ```python\n",
        "     transform = A.Compose([\n",
        "         A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                     std=(0.229, 0.224, 0.225)),\n",
        "         ToTensorV2(),\n",
        "     ])\n",
        "     ```  \n",
        "   - **Why?** Centers input data around zero mean and unit variance, accelerating optimizer convergence and stabilizing gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw1ijbZSR6j4"
      },
      "source": [
        "### 3.1 Remove Images with Empty Labels\n",
        "\n",
        "In our dataset, some label files (`.txt`) are 0 bytes (empty), which causes errors when YOLO attempts to load them. We must delete those label files and their corresponding images before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:23:59.659305Z",
          "iopub.status.busy": "2025-05-26T06:23:59.658993Z",
          "iopub.status.idle": "2025-05-26T06:23:59.671960Z",
          "shell.execute_reply": "2025-05-26T06:23:59.671151Z",
          "shell.execute_reply.started": "2025-05-26T06:23:59.659280Z"
        },
        "id": "abCVtZ0KkYZv",
        "outputId": "24f5f2c0-9bd2-452e-ae6b-4eae5eecd061",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0330_JPG.rf.820e5767005a8cf928a9e0680f2bb211.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0330_JPG.rf.820e5767005a8cf928a9e0680f2bb211.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1145_JPG.rf.c501a5873b27b49a7a67bebc42bf9bdb.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1145_JPG.rf.c501a5873b27b49a7a67bebc42bf9bdb.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0213_JPG.rf.39d1e47fe401ff4f0ed7becec0fc997c.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0213_JPG.rf.39d1e47fe401ff4f0ed7becec0fc997c.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1143_JPG.rf.3f2658656975cc5d3970f6d033fc5483.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1143_JPG.rf.3f2658656975cc5d3970f6d033fc5483.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1145_JPG.rf.e660dc4161e55a9d5e9ae4339cb033be.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1145_JPG.rf.e660dc4161e55a9d5e9ae4339cb033be.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0330_JPG.rf.bbed16e0eef3b324a50540258f5b24ab.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0330_JPG.rf.bbed16e0eef3b324a50540258f5b24ab.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1144_JPG.rf.0712790579c1f973c42e695667058225.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1144_JPG.rf.0712790579c1f973c42e695667058225.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0213_JPG.rf.6ae88337d39608b8566aa7a0a3c042df.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0213_JPG.rf.6ae88337d39608b8566aa7a0a3c042df.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1143_JPG.rf.b9c0e13a4d580af35c60fad2303e3f74.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1143_JPG.rf.b9c0e13a4d580af35c60fad2303e3f74.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0330_JPG.rf.745cebf4e282b04cb36dd50cdad81f94.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0330_JPG.rf.745cebf4e282b04cb36dd50cdad81f94.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1144_JPG.rf.8a8440c10b4ca467478b0f9285202c46.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1144_JPG.rf.8a8440c10b4ca467478b0f9285202c46.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1143_JPG.rf.73a319d7c2648598ac74b4a3222f4927.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1143_JPG.rf.73a319d7c2648598ac74b4a3222f4927.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0213_JPG.rf.c3d06634ba033bc2aa45b4196177733f.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0213_JPG.rf.c3d06634ba033bc2aa45b4196177733f.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0214_JPG.rf.256ab89188a6a009f654161bcc04fc64.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0214_JPG.rf.256ab89188a6a009f654161bcc04fc64.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0214_JPG.rf.4ed66c48b590e58096cb5bdd7007ef31.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0214_JPG.rf.4ed66c48b590e58096cb5bdd7007ef31.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1144_JPG.rf.8da9645619107724e73213f099f6ea98.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1144_JPG.rf.8da9645619107724e73213f099f6ea98.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_0214_JPG.rf.ff901d83bb7227dd3800eed1eb0aa6dc.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_0214_JPG.rf.ff901d83bb7227dd3800eed1eb0aa6dc.txt\n",
            "Deleted image file: /kaggle/working/tomato_leaf_dataset/train/images/IMG_1145_JPG.rf.73bb1c1d25d5dea40cf9b10b9f18bca3.jpg\n",
            "Deleted label file: /kaggle/working/tomato_leaf_dataset/train/labels/IMG_1145_JPG.rf.73bb1c1d25d5dea40cf9b10b9f18bca3.txt\n"
          ]
        }
      ],
      "source": [
        "# Iterate over every file in the training label directory\n",
        "for filename in os.listdir(label_folder):\n",
        "    # Only consider files that end with .txt (YOLO label files)\n",
        "    if filename.endswith(\".txt\"):\n",
        "        # Construct the full path to this label file\n",
        "        label_file_path = os.path.join(label_folder, filename)\n",
        "\n",
        "        # If the label file is empty (size == 0 bytes), we need to remove it and its image\n",
        "        if os.path.getsize(label_file_path) == 0:\n",
        "            # Determine the corresponding image filename by replacing \".txt\" with \".jpg\"\n",
        "            image_name = filename[:-4] + '.jpg'\n",
        "            image_file_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "            # If that image exists, attempt to delete it\n",
        "            if os.path.exists(image_file_path):\n",
        "                try:\n",
        "                    os.remove(image_file_path)\n",
        "                    print(f\"Deleted image file: {image_file_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to delete image file: {image_file_path} - {e}\")\n",
        "\n",
        "            # Now delete the empty label file itself\n",
        "            try:\n",
        "                os.remove(label_file_path)\n",
        "                print(f\"Deleted label file: {label_file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to delete label file: {label_file_path} - {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Data Augmentation\n",
        "\n",
        "To improve generalisation on a relatively small dataset and make our model robust to variations in lighting, orientation, and noise, we apply a suite of on-the-fly augmentations during training. All augmentations are implemented using Albumentations and applied **only** to the training split (not the validation or test sets).\n",
        "\n",
        "Below is a detailed explanation of what each augmentation does and why it is beneficial:\n",
        "\n",
        "1. **Shift, Scale & Rotate**  \n",
        "   - **What it does:**  \n",
        "     - Randomly shifts (translates) the image horizontally and vertically by a small fraction of its size.  \n",
        "     - Randomly scales (zooms) the image in or out by a small percentage.  \n",
        "     - Randomly rotates the image by a limited number of degrees (e.g., ±15°).  \n",
        "   - **Why it helps:**  \n",
        "     - **Shift/Translation:** Simulates slight changes in camera position or leaf placement, ensuring that the detector does not rely on objects always appearing in the centre of the image.  \n",
        "     - **Scale (Zoom):** Represents variations in camera distance, allowing the model to handle leaves that appear slightly larger or smaller in the frame.  \n",
        "     - **Rotation:** Ensures robustness to leaves that are tilted or photographed at different angles, which is important because farmers or field conditions will not always produce perfectly aligned images.  \n",
        "\n",
        "2. **Random Brightness & Contrast**  \n",
        "   - **What it does:**  \n",
        "     - Randomly increases or decreases the brightness of the image.  \n",
        "     - Randomly increases or decreases the contrast of the image.  \n",
        "   - **Why it helps:**  \n",
        "     - **Brightness Variations:** Simulates lighting changes, such as those between cloudy and sunny days, or indoor and outdoor photography.  \n",
        "     - **Contrast Variations:** Simulates differences in camera exposure and environmental lighting (e.g., shadows, reflections).  \n",
        "     - By teaching the model to ignore overall lighting differences, it can focus on the actual lesion textures rather than being sensitive to irrelevant brightness shifts.  \n",
        "\n",
        "3. **Hue, Saturation & Value (HSV) Jitter**  \n",
        "   - **What it does:**  \n",
        "     - Randomly shifts the hue of the image within a small range (slightly altering leaf colour tones).  \n",
        "     - Randomly shifts saturation, making colours more or less intense.  \n",
        "     - Randomly shifts the value (brightness channel in HSV space), producing colour-based variations beyond simple brightness/contrast.  \n",
        "   - **Why it helps:**  \n",
        "     - **Hue Shifts:** Simulate slight colour deviations caused by different camera sensors or post-processing (e.g., a leaf might appear slightly more yellowish under certain lighting conditions).  \n",
        "     - **Saturation Shifts:** Account for variations in the appearance of leaf colours, which can change with age or disease progression, making them appear more vivid or muted.  \n",
        "     - **Value Shifts:** Provide additional brightness variability in the colour space, complementing the brightness and contrast adjustments.  \n",
        "     Overall, HSV jitter ensures that the network learns to detect lesions based on texture and shape rather than absolute colour values.  \n",
        "\n",
        "4. **Gaussian Noise**  \n",
        "   - **What it does:**  \n",
        "     - Adds random Gaussian (normally distributed) noise to pixel values, making the image appear grainy.  \n",
        "   - **Why it helps:**  \n",
        "     - Reflects real‐world sensor noise or compression artifacts (e.g., JPEG artifacts or camera sensor grain).  \n",
        "     - Forces the model to learn robust features that are not disrupted by small random pixel fluctuations.  \n",
        "     - Helps prevent overfitting to immaculate images, as many real-world field images will contain noise or blur.  \n",
        "\n",
        "5. **Random Scaling (Zoom In / Zoom Out)**  \n",
        "   - **What it does:**  \n",
        "     - Independently scales the entire image by a small random factor (e.g., between 90% and 110% of its original size), then re‐pads or crops to restore the final dimensions.  \n",
        "   - **Why it helps:**  \n",
        "     - Simulates changes in camera zoom or distance beyond uniform letterboxing.  \n",
        "     - Ensures that the model can detect lesions even if they appear relatively larger or smaller than average.  \n",
        "     - Complements the “Shift, Scale & Rotate” augmentation by sometimes applying a pure zoom operation without rotation or translation.  \n",
        "\n",
        "---\n",
        "\n",
        "### Why These Augmentations Matter\n",
        "\n",
        "- **Dataset Size Limitation:** With only a few hundred training images, the model risks overfitting to specific leaf orientations, lighting conditions, and background textures.  \n",
        "- **Real-World Variability:** In practice, tomato leaves may be photographed at different times of day, in varying weather conditions, or with different camera devices. Augmentations simulate these variations artificially, resulting in a detector that generalises more effectively to new images.  \n",
        "- **Small Lesion Detection:** Many tomato‐leaf diseases manifest as tiny spots or subtle texture changes. By applying geometric and colour-space augmentations, we ensure that the network does not “memorise” the exact appearance of lesions but instead focuses on invariant features such as shape, relative contrast, and texture patterns.\n",
        "\n",
        "By combining these augmentations during training, we create a richer set of training examples that help our custom detector become more robust and accurate when deployed in real agricultural settings."
      ],
      "metadata": {
        "id": "l02pNLvyXExN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qnd4_yWR6j4"
      },
      "source": [
        "### 4.1 Data Augmentation & Custom Dataset\n",
        "\n",
        "Here we define an Albumentations pipeline to apply random augmentations and then build a `CustomYOLODataset` class that overrides `__getitem__` to:\n",
        "1. Load each image and its YOLO-format labels.\n",
        "2. Split labels into class IDs and bounding boxes.\n",
        "3. Apply our augmentation pipeline (including normalization and tensor conversion).\n",
        "4. Repackage the augmented boxes and classes back into a PyTorch tensor.\n",
        "\n",
        "This ensures that during training, every batch sees randomly perturbed images (shift, rotate, color jitter, noise, scale) along with correctly remapped bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:04.635107Z",
          "iopub.status.busy": "2025-05-26T06:24:04.634280Z",
          "iopub.status.idle": "2025-05-26T06:24:04.653124Z",
          "shell.execute_reply": "2025-05-26T06:24:04.652249Z",
          "shell.execute_reply.started": "2025-05-26T06:24:04.635075Z"
        },
        "id": "7ByQJ_RxkYZv",
        "outputId": "a5765e2e-4b98-48b9-cda3-eb84461a0785",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipykernel_165/3059107224.py:7: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n"
          ]
        }
      ],
      "source": [
        "# Compose a sequence of Albumentations transforms, including augmentation, normalization, and tensor conversion\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        # Randomly shift, scale, and rotate the image (±10% shift, ±20% scale, ±30° rotation) half the time\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.1,\n",
        "            scale_limit=0.2,\n",
        "            rotate_limit=30,\n",
        "            p=0.5\n",
        "        ),\n",
        "        # Randomly adjust brightness and contrast half the time (±30% variation)\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.3,\n",
        "            contrast_limit=0.3,\n",
        "            p=0.5\n",
        "        ),\n",
        "        # Randomly jitter hue, saturation, and value half the time\n",
        "        A.HueSaturationValue(\n",
        "            hue_shift_limit=20,\n",
        "            sat_shift_limit=30,\n",
        "            val_shift_limit=20,\n",
        "            p=0.5\n",
        "        ),\n",
        "        # Randomly add Gaussian noise (variance between 10 and 50) 30% of the time\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "        # Always randomly rescale the image by a factor between -10% (zoom out) and +50% (zoom in)\n",
        "        A.RandomScale(\n",
        "            scale_limit=(-0.1, 0.5),\n",
        "            interpolation=cv2.INTER_LINEAR,\n",
        "            p=1.0\n",
        "        ),\n",
        "        # Normalize pixel values to zero mean, unit variance per channel\n",
        "        A.Normalize(),\n",
        "        # Convert the final augmented image into a PyTorch FloatTensor of shape (3, H, W)\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    # Tell Albumentations that our bounding boxes are in YOLO format (x_center, y_center, w, h normalized)\n",
        "    # and that their corresponding class IDs are in the 'cls' field\n",
        "    bbox_params=A.BboxParams(format='yolo', label_fields=['cls'])\n",
        ")\n",
        "\n",
        "\n",
        "class CustomYOLODataset(YOLODataset):\n",
        "    \"\"\"\n",
        "    Subclass of YOLODataset that:\n",
        "    1. Loads the raw image (BGR) and YOLO-format labels.\n",
        "    2. Splits labels into class IDs and bounding boxes.\n",
        "    3. Applies the Albumentations pipeline to both image and boxes.\n",
        "    4. Returns the augmented image tensor and a [N,5] label tensor.\n",
        "    \"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        # 1) Load raw image & label via the base class method\n",
        "        img, _    = self.load_image(idx)   # img: BGR uint8 of shape (H, W, 3)\n",
        "        labels    = self.load_label(idx)   # labels: numpy array shape (N, 5) or empty array\n",
        "\n",
        "        # 2) Parse labels into lists of class IDs and bounding boxes\n",
        "        if labels.size:\n",
        "            cls    = labels[:, 0].astype(int).tolist()    # class IDs (e.g. [0, 3, 1, ...])\n",
        "            bboxes = labels[:, 1:].tolist()               # bounding boxes [[x_c, y_c, w, h], ...]\n",
        "        else:\n",
        "            cls, bboxes = [], []\n",
        "\n",
        "        # 3) Convert BGR→RGB (Albumentations expects RGB input)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 4) Apply the augmentation pipeline, passing in both the image and its boxes+classes\n",
        "        augmented = transform(image=img_rgb, bboxes=bboxes, cls=cls)\n",
        "        img2    = augmented['image']    # augmented image as FloatTensor (3, H, W), values ~N(0,1)\n",
        "        cls2    = augmented['cls']      # possibly shuffled/unchanged class list\n",
        "        bboxes2 = augmented['bboxes']   # updated bounding boxes after augmentation\n",
        "\n",
        "        # 5) Repack the augmented boxes and classes into a single [N,5] tensor\n",
        "        if bboxes2:\n",
        "            # Stack each (class, x_center, y_center, width, height) into a tensor\n",
        "            lab = torch.tensor(\n",
        "                [[c, *b] for c, b in zip(cls2, bboxes2)],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "        else:\n",
        "            # If no boxes remain after augmentation, return an empty (0,5) tensor\n",
        "            lab = torch.zeros((0, 5), dtype=torch.float32)\n",
        "\n",
        "        # 6) Return the image tensor and its corresponding label tensor\n",
        "        return img2, lab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evolution\n",
        "\n",
        "Throughout this project, we iteratively refined our approach to strike a balance between detection accuracy, model size, and inference speed. Below, we describe each successive model, the architectural changes we made, the reasons behind those changes, and their impact on performance.\n",
        "\n",
        "### 5.1 Model 1: Custom CNN Classifier (Assignment 2)\n",
        "\n",
        "**Architecture Overview:**  \n",
        "\n",
        "  ```python\n",
        "  class CustomImageClassifier(ImageClassificationBase):\n",
        "      def __init__(self, in_channels, num_classes):\n",
        "          super().__init__()\n",
        "          self.conv1 = conv_block(in_channels, 64)\n",
        "          self.conv2 = conv_block(64, 128, pool=True)\n",
        "          self.res1  = nn.Sequential(conv_block(128,128), conv_block(128,128))\n",
        "          self.conv3 = conv_block(128, 256, pool=True)\n",
        "          self.conv4 = conv_block(256, 512, pool=True)\n",
        "          self.res2  = nn.Sequential(conv_block(512,512), conv_block(512,512))\n",
        "          self.classifier = nn.Sequential(nn.MaxPool2d(4), nn.Flatten(), nn.Linear(512, num_classes))\n",
        "      def forward(self, xb):\n",
        "          out = self.conv1(xb)\n",
        "          out = self.conv2(out)\n",
        "          out = self.res1(out) + out\n",
        "          out = self.conv3(out)\n",
        "          out = self.conv4(out)\n",
        "          out = self.res2(out) + out\n",
        "          out = self.classifier(out)\n",
        "          return out\n",
        " ```          \n",
        "          \n",
        "- A lightweight, nine‐layer convolutional network with residual connections:  \n",
        "  - **Conv Block 1:** 64 filters  \n",
        "  - **Conv Block 2:** 128 filters + max‐pool  \n",
        "  - **Residual Block 1:** two consecutive 128‐filter conv blocks (skip connection adds input)  \n",
        "  - **Conv Block 3:** 256 filters + max‐pool  \n",
        "  - **Conv Block 4:** 512 filters + max‐pool  \n",
        "  - **Residual Block 2:** two consecutive 512‐filter conv blocks (skip connection adds input)  \n",
        "  - **Classifier Head:** global max‐pool → flatten → linear layer mapping to 7 classes  \n",
        "\n",
        "**Training & Purpose:**  \n",
        "- Trained to classify each entire image into one of seven categories (six disease types plus Healthy).  \n",
        "- When repurposed for weak localization (e.g., Grad‐CAM), we extracted coarse activation maps and derived bounding boxes.\n",
        "\n",
        "**Performance & Limitations:**  \n",
        "- **Measured Box Precision:** ≈ 0.50  \n",
        "- **Measured mAP@50:** < 0.50  \n",
        "\n",
        "1. **No Explicit Detection Head:** The architecture only outputs class probabilities. There is no mechanism to predict exact bounding‐box coordinates, so any localization is approximate.  \n",
        "2. **Coarse Feature Maps:** The spatial resolution of feature maps is too low to detect small lesions reliably; tiny spots often “disappear” after multiple pooling layers.  \n",
        "3. **Fails Baseline Requirements:** Did not achieve Box P ≥ 0.75 or mAP@50 ≥ 0.75, so this model cannot serve as our detector.\n",
        "\n",
        "Because Model 1 cannot localise lesions precisely, we needed to transition to a proper object detection framework.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.2 Model 2: Pretrained YOLO-11M Fine-Tuning\n",
        "\n",
        "**Approach:**  \n",
        "- Loaded the official YOLO-11M “medium” checkpoint trained on COCO (80 classes).  \n",
        "- Replaced the final detection layer to predict **nc = 7** classes.  \n",
        "- Fine‐tuned the entire network on our tomato‐leaf dataset for 50–100 epochs, keeping the exact image size and data augmentations.\n",
        "\n",
        "**Performance:**  \n",
        "- **Box Precision:** ~ 0.80  \n",
        "- **mAP@50:** ~ 0.81  \n",
        "- **Inference Speed:** ~ 25–30 ms/image on a Tesla P100 GPU  \n",
        "- **Model Size (weights only):** ~ 150 MB  \n",
        "\n",
        "**Drawbacks & Rationale for Change:**  \n",
        "1. **Assignment Violation:** The project specification prohibits the use of a pre-trained, off-the-shelf object detector without major architectural modifications.  \n",
        "2. **Resource-Heavy:** With an inference time of ~150 MB, this model is too large and slow for practical on-device deployment (e.g., in-field agricultural settings with limited compute resources).  \n",
        "3. **Black-Box Complexity:** Relying on a black-box pre-trained model limits our ability to explain or adapt internal feature extraction specifically for tomato-leaf textures.\n",
        "\n",
        "Although Model 2 exceeded the baseline accuracy targets, it failed to satisfy the “build from scratch” requirement and was impractical for edge deployment. Therefore, we designed a lighter, custom detector from the ground up.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.3 Model 3: Custom YOLO-11M (C2f + SPPF + C2PSA)\n",
        "\n",
        "**Objective:**  \n",
        "- Build a YOLO-inspired detector from scratch that (a) meets or exceeds baseline metrics, (b) is significantly smaller than YOLO-11M, and (c) runs faster at inference time.\n",
        "\n",
        "**Architectural Changes:**  \n",
        "1. **C2f Blocks (2‐Conv Fusion):**  \n",
        "   - **Original (C3f):** Each bottleneck had three convolutional layers.  \n",
        "   - **Modified (C2f):** We replaced every C3f block with a C2f block containing only two convolutions.  \n",
        "   - **Effect:** Reduces parameters and FLOPs by ~ 25 % per block while preserving effective feature fusion. The network remains expressive for capturing texture features but is noticeably smaller.\n",
        "\n",
        "2. **SPPF (Spatial Pyramid Pooling – Fast):**  \n",
        "   At the end of the backbone, we apply three parallel max-pool layers (kernel sizes 5×5, 9×9, 13×13) with the same stride and padding, then concatenate their outputs with the original feature map.  \n",
        "   - **Effect:** Captures multi‐scale context from fine lesion edges (local scale) to overall leaf shape (global scale)without resorting to expensive dilated convolutions. Improves detection of varying lesion sizes with minimal parameter overhead.\n",
        "\n",
        "3. **C2PSA (2‐Conv Fusion + Polarized Self‐Attention):**  \n",
        "   - Immediately before the detection head, we insert a C2f block (with 1024 channels) followed by a Polarized Self‐Attention (PSA) module.  \n",
        "     - **Channel Attention:** Learns per‐channel weights to highlight filters that detect disease textures (e.g., spotting characteristic edges).  \n",
        "     - **Spatial Attention:** Learns a heatmap over spatial locations to focus on lesion edges and suppress background.  \n",
        "   - **Effect:** Emphasizes high‐frequency texture details (tiny spots/edges), which is critical for localizing small lesions that might otherwise be missed.\n",
        "\n",
        "**Training Details:**  \n",
        "- Trained from scratch on our tomato‐leaf dataset (no COCO pretraining).  \n",
        "- Used the same hyperparameters as a standard YOLO-style baseline:  \n",
        "  - **Input Size:** 640 × 640  \n",
        "  - **Batch Size:** 16  \n",
        "  - **Optimizer:** Adam, lr = 1 × 10⁻⁴  \n",
        "  - **Epochs:** 100 with early‐stopping (patience 40)  \n",
        "  - **Data Augmentations:** As described in Section 4  \n",
        "  - **Loss Functions:** Standard YOLO detection loss (box regression + objectness + classification)\n",
        "\n",
        "**Performance & Impact:**  \n",
        "- **Box Precision:** ~ 0.76  \n",
        "- **mAP@50:** ~ 0.81  \n",
        "- **Model Parameters:** ~ 28.2 M (vs. ~ 44 M for standard YOLO-11M)  \n",
        "- **Inference Speed:** ~ 22 ms/image (vs. ~ 30 ms/image for off‐the‐shelf YOLO-11M)  \n",
        "\n",
        "1. **Meets Baseline Requirements:** Achieved Box P ≥ 0.75 and mAP@50 ≥ 0.75 using a fully custom architecture.  \n",
        "2. **Reduced Size & Faster Inference:** ~ 36 % fewer parameters and ~ 27 % faster inferencesuitable for on‐device deployment.  \n",
        "3. **Improved Feature Focus:** The C2PSA block effectively directs the model’s attention to high‐frequency lesion patterns, which is essential for detecting very small or low‐contrast disease spots.\n",
        "\n",
        "By designing Model 3, we satisfied both the assignment’s requirement to build from scratch and the practical constraint of creating a lightweight, high‐performance detector.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.4 Model 4: Custom YOLO-11M + Fourier-Based Regularization\n",
        "\n",
        "**Objective:**  \n",
        "- Further improve localization of subtle, tiny lesions by incorporating a frequency‐domain penalty during training without increasing inference cost or altering the architecture.\n",
        "\n",
        "**What Changed from Model 3:**  \n",
        "- **Architecture:** Identical to Model 3 (C2f + SPPF + C2PSA).  \n",
        "- **New Component:** We introduce a **FourierLoss** term during training that encourages the network to preserve high‐frequency information corresponding to lesion boundaries.\n",
        "\n",
        "**FourierLoss Computation:**  \n",
        "1. **Convert Input Patches to Grayscale:** For each ground‐truth bounding box, crop the corresponding region from the original image and convert it to a single‐channel (grayscale) patch.  \n",
        "2. **2D Real FFT → Magnitude Spectrum:** Compute the two‐dimensional Fast Fourier Transform of each grayscale patch; take the magnitude to obtain frequency‐domain representation.  \n",
        "3. **Mask Low Frequencies:** Zero out or discard the lowest 80 % of frequency coefficients, leaving only the top 20 % of high‐frequency magnitudes (which correspond to edges and fine textures).  \n",
        "4. **Feature Map FFT:** From Model 3’s backbone, take the corresponding feature map (after the final PSA block), compute its 2D FFT, and obtain the magnitude spectrum.  \n",
        "5. **Compute High-Frequency Energy:** Similarly, mask low frequencies in the feature-map spectrum to isolate high-frequency components.  \n",
        "6. **L2 Penalty on High‐Frequency Mismatch:** Compute the mean‐squared error between the high‐frequency magnitudes of the image patch and the feature map. Multiply by a weight λ = 0.1 and add to the standard detection loss.  \n",
        "\n",
        "In other words:  \n",
        "$$\n",
        "L_{\\mathrm{Fourier}} = \\frac{1}{N_{\\mathrm{boxes}}} \\sum_{\\mathrm{each\\ box}} \\Bigl\\lVert\\,\\mathrm{highFreq}\\bigl(\\mathrm{FFT}(\\mathrm{imgPatch})\\bigr)\\;-\\;\\mathrm{highFreq}\\bigl(\\mathrm{FFT}(\\mathrm{featMap})\\bigr)\\Bigr\\rVert_{2}^{2}\\,,\n",
        "\\quad\n",
        "L_{\\mathrm{total}} = L_{\\mathrm{det}} + 0.1 \\times L_{\\mathrm{Fourier}}\\,.\n",
        "$$\n",
        "\n",
        "**Rationale:**  \n",
        "- **Lesion Boundaries ↔ High Frequencies:** Disease spots and mould patterns often manifest as sharp intensity changes or fine-texture anomalies, i.e., high-frequency components in the Fourier domain.  \n",
        "- **Preserve Textural Details:** By penalising the network when its internal feature maps lose these high frequencies, we force it to retain sharper edges and finer details, improving its ability to delineate small lesions.  \n",
        "- **No Inference Overhead:** FourierLoss only affects training; at inference time, the architecture is unchanged, so model size and speed remain identical to Model 3.\n",
        "\n",
        "**Performance Gains:**  \n",
        "\n",
        "| Metric             | Model 3 (Baseline) | Model 4 (+Fourier) | Δ (Absolute) |\n",
        "|--------------------|--------------------|--------------------|--------------|\n",
        "| Box Precision      | 0.7580             | 0.7816             | +0.0236      |\n",
        "| mAP@50             | 0.8092             | 0.8328             | +0.0236      |\n",
        "| F1 Score @ IoU 0.5 | 0.7086             | 0.7354             | +0.0268      |\n",
        "| mAP@50–95          | 0.5150             | 0.5370             | +0.0220      |\n",
        "\n",
        "- **Inference Speed:** Remains ~ 22 ms/image (unchanged).  \n",
        "- **Model Size:** Still ~ 28.2 M parameters.\n",
        "\n",
        "1. **Sharper Localization:** Adding FourierLoss results in qualitatively tighter bounding boxes around small, low‐contrast lesions.  \n",
        "2. **Improved Metrics:** Consistent ~ 2–3 percentage‐point gains across all core metrics, confirming the value of frequency‐domain regularization.  \n",
        "3. **Final Deliverable:** Model 4 is both lightweight and accurate, meeting all performance targets (Box P > 0.75, mAP@50 > 0.75, F1 > 0.70) and demonstrating enhanced small‐lesion detection capability.\n"
      ],
      "metadata": {
        "id": "-Vh0p8v3ZoEf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ikaZxmR6j5"
      },
      "source": [
        "### 5.1 Writing the YOLO `data.yaml` Configuration\n",
        "\n",
        "This section creates a YAML file that tells YOLOv8 where to find our training and validation images, how many classes there are, and what each class index means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:08.405918Z",
          "iopub.status.busy": "2025-05-26T06:24:08.405409Z",
          "iopub.status.idle": "2025-05-26T06:24:08.412817Z",
          "shell.execute_reply": "2025-05-26T06:24:08.411994Z",
          "shell.execute_reply.started": "2025-05-26T06:24:08.405894Z"
        },
        "id": "fsMk3dlpkYZw",
        "outputId": "e3abe3a0-d11a-4ee3-cc30-fbe04b52c496",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML file '/kaggle/working/tomato_leaf.yaml' created successfully.\n"
          ]
        }
      ],
      "source": [
        "def create_yaml_file(data, filename):\n",
        "    \"\"\"\n",
        "    Utility function to write a Python dictionary `data` into a YAML file named `filename`.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, 'w') as file:\n",
        "            # Dump the dictionary into the file in standard YAML format (no flow style)\n",
        "            yaml.dump(data, file, default_flow_style=False)\n",
        "        print(f\"YAML file '{filename}' created successfully.\")\n",
        "    except Exception as e:\n",
        "        # If anything goes wrong (e.g., permission error), print the error message\n",
        "        print(f\"Error creating YAML file: {e}\")\n",
        "\n",
        "\n",
        "# Define the YOLO data configuration as a Python dictionary:\n",
        "data = {\n",
        "    # Path to the folder containing training images (relative to where YOLO is run)\n",
        "    \"train\": f\"{base_output_path}/tomato_leaf_dataset/train/images\",\n",
        "    # Path to the folder containing validation images (we use the \"test\" split as val here)\n",
        "    \"val\":   f\"{base_output_path}/tomato_leaf_dataset/test/images\",\n",
        "    # Number of object classes (0 through 6)\n",
        "    \"nc\":    7,\n",
        "    # Class names (you can replace '0','1',... with descriptive names if desired)\n",
        "    \"names\": ['0', '1', '2', '3', '4', '5', '6']\n",
        "}\n",
        "\n",
        "# Construct the full path for the YAML file\n",
        "yaml_path = f\"{base_output_path}/tomato_leaf.yaml\"\n",
        "# Call our utility function to write out `tomato_leaf.yaml`\n",
        "create_yaml_file(data, yaml_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d4Xoak0R6j5"
      },
      "source": [
        "### 5.2 Define & Write Custom YOLO-11M Model Configuration\n",
        "\n",
        "Below we construct a Python dictionary (`yolo11_config`) that fully describes our custom YOLO-11M architecture. We then serialize it to a YAML file (`yolo11m.yaml`) so YOLOv8 can load and instantiate the model exactly as defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:10.199128Z",
          "iopub.status.busy": "2025-05-26T06:24:10.198855Z",
          "iopub.status.idle": "2025-05-26T06:24:10.211784Z",
          "shell.execute_reply": "2025-05-26T06:24:10.211023Z",
          "shell.execute_reply.started": "2025-05-26T06:24:10.199107Z"
        },
        "id": "c66Z2Nl7kYZw",
        "outputId": "f6e5dc22-91da-4f79-a9e9-64f020d213bd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML file '/kaggle/working/yolo11m.yaml' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# 1) Define a dictionary describing our custom YOLO architecture\n",
        "yolo11_config = {\n",
        "\n",
        "    # Number of object classes (7 tomato-leaf disease categories)\n",
        "    \"nc\": 7,\n",
        "\n",
        "    # 2) Anchor “scales” dictionary (stride / anchor size per feature map level)\n",
        "    \"scales\": {\n",
        "        # Each key (n, s, m, l, x) corresponds to a scale/tier in the detection head.\n",
        "        # Format: [scale_x, scale_y, feature_map_channels]\n",
        "        \"n\": [0.50, 0.25, 1024],   # \"nano\"-scale: downsample factor 0.50, upsample 0.25, 1024 channels\n",
        "        \"s\": [0.50, 0.50, 1024],   # \"small\"-scale: ...\n",
        "        \"m\": [0.50, 1.00, 512],    # \"medium\" scale\n",
        "        \"l\": [1.00, 1.00, 512],    # \"large\" scale\n",
        "        \"x\": [1.00, 1.50, 512]     # \"x-large\" scale\n",
        "    },\n",
        "\n",
        "    # 3) Backbone definition: list of layers that extract features from input images\n",
        "    \"backbone\": [\n",
        "        # [from_idx, num_repeats, block_type, [out_channels, kernel_size, stride]]\n",
        "        [-1, 1, \"Conv\", [64,  3, 2]],     # 1) Standard Conv2d → BN → Act (64 filters, 3×3 kernel, stride 2)\n",
        "        [-1, 1, \"Conv\", [128, 3, 2]],     # 2) Conv2d (128 filters, stride 2) — further downsamples\n",
        "\n",
        "        [-1, 2, \"C2f\",  [256, True]],     # 3) C2f fusion block: 2 conv layers, 256 output channels, with residual (True)\n",
        "        [-1, 1, \"Conv\", [256, 3, 2]],     # 4) Conv2d (256 filters, stride 2)\n",
        "\n",
        "        [-1, 2, \"C2f\",  [512, True]],     # 5) Another C2f block: 512 channels, with residual\n",
        "        [-1, 1, \"Conv\", [512, 3, 2]],     # 6) Conv2d (512 filters, stride 2)\n",
        "\n",
        "        [-1, 2, \"C2f\",  [512, True]],     # 7) C2f again (512 channels), capturing mid-level features\n",
        "        [-1, 1, \"Conv\", [1024, 3, 2]],    # 8) Conv2d (1024 filters, stride 2)—deep features\n",
        "\n",
        "        [-1, 2, \"C2f\",  [1024, True]],    # 9) C2f with 1024 channels, fully capturing high-level info\n",
        "        [-1, 1, \"SPPF\", [1024, 5]],       # 10) SPPF block: spatial pyramid pooling with 5×5, 9×9, 13×13 kernels\n",
        "        [-1, 2, \"C2PSA\",[1024]]           # 11) C2PSA: 2-conv fusion (1024 channels) + Polarized Self-Attention\n",
        "    ],\n",
        "\n",
        "    # 4) Head definition: layers that upsample, concatenate, and detect\n",
        "    \"head\": [\n",
        "        # Multi-scale detection head that merges feature maps from different levels\n",
        "        [-1, 1, \"nn.Upsample\", [None, 2, \"nearest\"]],   # 1) Upsample the last backbone feature by 2×\n",
        "        [[-1, 6], 1, \"Concat\", [1]],                    # 2) Concatenate the upsampled feature with backbone node #6\n",
        "\n",
        "        [-1, 2, \"C2f\", [512, False]],                   # 3) C2f block (512 channels, no residual) to refine combined features\n",
        "\n",
        "        [-1, 1, \"nn.Upsample\", [None, 2, \"nearest\"]],   # 4) Upsample again by 2×\n",
        "        [[-1, 4], 1, \"Concat\", [1]],                    # 5) Concatenate with backbone node #4\n",
        "\n",
        "        [-1, 2, \"C2f\", [256, False]],                   # 6) C2f block (256 channels, no residual)\n",
        "\n",
        "        [-1, 1, \"Conv\", [256, 3, 2]],                   # 7) Conv2d (256 filters, 3×3 kernel, stride 2) – downsample\n",
        "\n",
        "        [[-1, 13], 1, \"Concat\", [1]],                   # 8) Concatenate with earlier head feature #13\n",
        "\n",
        "        [-1, 2, \"C2f\", [512, False]],                   # 9) C2f (512 channels) to refine again\n",
        "\n",
        "        [-1, 1, \"Conv\", [512, 3, 2]],                   # 10) Conv2d (512 filters, stride 2) – further downsample\n",
        "\n",
        "        [[-1, 10], 1, \"Concat\", [1]],                   # 11) Concatenate with feature #10\n",
        "\n",
        "        [-1, 2, \"C2f\", [1024, True]],                   # 12) C2f (1024 channels, with residual) – final fusion\n",
        "\n",
        "        [[16, 19, 22], 1, \"Detect\", [\"nc\"]]              # 13) YOLO Detect layer: predicts boxes, objectness, class probs\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 5) Write the model configuration to a YAML file so YOLOv8 can load it\n",
        "yaml_model_path = f\"{base_output_path}/yolo11m.yaml\"\n",
        "create_yaml_file(yolo11_config, yaml_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw2fTr3AR6j5"
      },
      "source": [
        "### Baseline Model & Training Configuration\n",
        "\n",
        "- **Architecture Chosen:** Custom YOLO-11M (defined in `yolo11m.yaml`), with:\n",
        "  1. **C2f Blocks** (2-conv fusion) instead of C3f to reduce parameters/FLOPs by ~25% per fusion block.  \n",
        "  2. **SPPF** (Spatial Pyramid Pooling Fast) to capture multi-scale context at the deepest layer.  \n",
        "  3. **C2PSA** (2-conv fusion + Polarized Self-Attention) for channel/spatial attention on high-frequency textures.\n",
        "\n",
        "- **Optimizer & LR Schedule:**  \n",
        "  - Optimizer = AdamW (auto-selected by Ultralytics)  \n",
        "  - `lr0` = 0.002, `lrf` = 0.01, `cos_lr=True` → LR decays from 0.002 → 2e-05 over 100 epochs using cosine schedule.  \n",
        "  - Weight decay = 0.0005 (default YAML).\n",
        "\n",
        "- **Augmentation Settings (YOLO.train args):**  \n",
        "  - `mosaic=0.5`, `mixup=0.2`, `copy_paste=0.2` to diversify training images.  \n",
        "  - Albumentations pipeline inside `CustomYOLODataset` applies random Shift/Scale/Rotate, Brightness/Contrast, Hue/Saturation/Value, Gaussian noise, RandomScale with 100% chance.\n",
        "\n",
        "- **Loss Hyperparameters:**  \n",
        "  - `iou=0.5`: Anchor IoU threshold during training (anchors with IoU ≥ 0.5 are positive).  \n",
        "  - `box=7.5`: Weight on CIoU/GIoU regression loss to emphasize precisely fitting tight boxes (small lesions).  \n",
        "  - `cls=0.5`: Weight on classification BCE loss to correctly identify disease class (7 categories).  \n",
        "  - `conf=0.25`: Objectness filter threshold during validation/inference (drop boxes with predicted objectness < 0.25).\n",
        "\n",
        "- **Batch & Epochs:**  \n",
        "  - Batch size = 4 per GPU (fits our 16 GB P100).  \n",
        "  - Trained for 100 epochs; early stopping patience = 40 (stop if no val improvement for 40 epochs).  \n",
        "  - `save_period=1`: save weights every epoch; best weights logged as `best.pt`.\n",
        "\n",
        "- **Validation During Training:**  \n",
        "  - We set `val=True`, so after each epoch, YOLO runs validation on the test split (`tomato_leaf_dataset/test/images`) and logs metrics (Box Precision, mAP@50, F1).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EACJ9CR6j5"
      },
      "source": [
        "## 6 Metric Selection and Computation\n",
        "\n",
        "In addition to Box Precision and mAP@50, we chose **F1 Score** as our extra evaluation metric to capture the balance between Precision and recall in the context of tomato‐leaf disease detection.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.1 Box Precision (Precision @ IoU ≥ 0.50)\n",
        "\n",
        "- **Definition:**  \n",
        "  For a given image, a predicted bounding box is considered a **True Positive (TP)** if its Intersection over Union (IoU) with a ground‐truth box is ≥ 0.50 and it has the correct class label. Otherwise:\n",
        "  - **False Positive (FP):** A predicted box either has IoU < 0.50 with all ground‐truth boxes of the same class class, or it matches the wrong class class.\n",
        "  - **False Negative (FN):** A ground‐truth box is not matched by any prediction with IoU ≥ 0.50 and the correct class class.\n",
        "\n",
        "- **Box Precision (per class class or overall):**\n",
        "  $$\n",
        "    \\text{Precision} \\;=\\; \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\quad (\\text{computed at IoU} \\ge 0.50)\n",
        "  $$\n",
        "  - Measures the proportion of predicted boxes that are correct.  \n",
        "  - High Precision means few false positives (i.e., the model rarely \"hallucinates\" lesions where none exist).\n",
        "\n",
        "- **Why Box Precision Matters for Tomato‐Leaf Detection:**  \n",
        "  - A **false positive** (predicting a lesion where none exists) wastes time and resources, for example, taking extra chemical samples or performing unnecessary inspections on healthy leaves.  \n",
        "  - In practice, farmers or agronomists rely on the detector to flag suspect leaves; if the detector generates many false alarms, trust in the system is compromised.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.2 mAP@50 (Mean Average Precision at IoU ≥ 0.50)\n",
        "\n",
        "- **Definition:**  \n",
        "  1. **Average Precision (AP) for a Single Class:**  \n",
        "     - Gather all predicted boxes for that class across the entire dataset, sorted by confidence score (descending).  \n",
        "     - Compute a Precision-Recall curve by sweeping through confidence thresholds:  \n",
        "       $$\n",
        "         \\text{Precision}(r) \\quad\\text{and}\\quad \\text{Recall}(r), \\quad r \\in [0,\\,1].\n",
        "       $$\n",
        "     - **AP@50** is the area under the Precision-Recall curve at IoU ≥ 0.50.  \n",
        "  2. **mAP@50:**  \n",
        "     $$\n",
        "       \\text{mAP@50} \\;=\\; \\frac{1}{C} \\sum_{c=1}^{C} \\text{AP}_{c}\\bigl(\\text{IoU} \\ge 0.50\\bigr),\n",
        "     $$\n",
        "     where \\( C = 7 \\) (the number of classes: six disease types + Healthy).\n",
        "\n",
        "- **Why mAP@50 Matters:**  \n",
        "  - Captures both Precision and recall **across all confidence thresholds**not just at a single operating point.  \n",
        "  - By averaging AP over all seven classes, mAP@50 accounts for per‐class performance, which is critical in a multi‐label scenario where some diseases (e.g., Leaf Mold, Black Spot) may be underrepresented.  \n",
        "  - A high mAP@50 implies that the detector is robust to threshold selection and maintains good overall detection quality.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.3 F1 Score @ IoU ≥ 0.50 (Extra Metric)\n",
        "\n",
        "- **Definition:**  \n",
        "  At a fixed IoU threshold (0.50), the F1 Score for a single class is the harmonic mean of Precision and recall:\n",
        "  $$\n",
        "    \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}},\n",
        "    \\quad\n",
        "    \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}},\n",
        "    \\quad\n",
        "    \\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}.\n",
        "  $$\n",
        "  We compute this at IoU ≥ 0.50 for each class class, and then average over all classes:\n",
        "  $$\n",
        "    \\text{Mean F1} = \\frac{1}{7} \\sum_{c=1}^{7} \\text{F1}_{c}\\bigl(\\text{IoU} \\ge 0.50\\bigr).\n",
        "  $$\n",
        "\n",
        "- **Rationale for Using F1 in Tomato‐Leaf Detection:**  \n",
        "  1. **Balance Between False Positives and False Negatives:**  \n",
        "     - A **false positive** (predicting a lesion that is not real) can trigger wasted effort.  \n",
        "     - A **false negative** (missing an actual lesion) can allow the disease to spread unchecked, potentially causing significant crop loss.  \n",
        "     - F1 penalizes both types of errors equally, ensuring the model cannot \"game\" one by sacrificing the other.  \n",
        "  2. **Highly Imbalanced Classes:**  \n",
        "     - Some disease categories (e.g., Leaf Mold, Black Spot) appear far less frequently than others.  \n",
        "     - In cases of class imbalance, AP alone can be misleading if a model simply ignores rare classes. F1 remains meaningful even when positive examples are scarce because it measures the trade‐off at a specific operating point (IoU ≥ 0.50).  \n",
        "  3. **Single‐Number Interpretability:**  \n",
        "     - While precision and recall metrics are informative, having a single scalar (F1) that only improves when both Precision and recall improve makes it easier to compare models concisely.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.4 How We Compute These Metrics\n",
        "\n",
        "1. **YOLOv8’s `results.to_df()` Method:**  \n",
        "   - After running validation (or test) inference, we call:\n",
        "     ```python\n",
        "     df = results.to_df()\n",
        "     ```\n",
        "     Where `df` is a pandas DataFrame containing, for each predicted box:\n",
        "     - `class` (0–6)  \n",
        "     - `confidence`  \n",
        "     - `xmin, ymin, xmax, ymax` (pixel coordinates)  \n",
        "     - `IoU` with its matched ground‐truth box (if any)  \n",
        "     - Precomputed per‐class metrics: `box-precision`, `box-recall`, and `box-f1` at IoU ≥ 0.50  \n",
        "\n",
        "2. **Box Precision and Recall (per class class):**  \n",
        "   - Extract the `box-precision` and `box-recall` columns from `df` and compute their mean across all predictions of that class.  \n",
        "   - This gives us precision\\(_c\\) and recall\\(_c\\) for each class \\( c \\).  \n",
        "\n",
        "3. **Per‐Class F1 (IoU ≥ 0.50):**  \n",
        "   - Extract the `box-f1` column for each class \\( c \\) and compute:\n",
        "     \"`python\n",
        "     f1_c = df[df['class'] == c]['box-f1'].mean()\n",
        "     ```\n",
        "   - This yields F1\\(_c\\) for class \\( c \\).\n",
        "\n",
        "4. **Mean F1 Across All Classes:**  \n",
        "   $$\n",
        "     \\text{Mean F1}\n",
        "     = \\frac{1}{7} \\sum_{c=0}^{6} \\Bigl( \\text{mean of } \\text{df['box-f1'][df['class']==c]} \\Bigr).\n",
        "   $$\n",
        "\n",
        "5. **mAP@50 (per Class → Mean):**  \n",
        "   - Use `results.box.map@50` (or similarly computed AP values) from `df`. For each class \\( c \\):\n",
        "     ```python\n",
        "     ap_c = df[df['class'] == c]['map@50'].mean()\n",
        "     ```\n",
        "   - Then, take the average:\n",
        "     $$\n",
        "       \\text{mAP@50}\n",
        "       = \\frac{1}{7} \\sum_{c=0}^{6} \\text{ap}_{c}.\n",
        "     $$\n",
        "\n",
        "6. **Aggregate \"Overall\" Metrics:**  \n",
        "   - **Overall Box Precision:** average of `box-precision` overall predictions (all classes).  \n",
        "   - **Overall mAP@50:** same as mAP definition above.  \n",
        "   - **Overall Mean F1:** as described in Step 4.\n",
        "\n",
        "By combining these three metricsBox Precision, mAP@50, and Mean F1we obtain a comprehensive view of our detector's performance:  \n",
        "- **Box Precision** ensures predictions are accurate at IoU ≥ 0.50.  \n",
        "- **mAP@50** measures how well the detector performs across confidence thresholds and classes.  \n",
        "- **Mean F1** quantifies the trade‐off between false positives and false negatives, which is crucial in the tomato‐leaf disease detection domain, where both types of errors carry real‐world costs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL6RoXzNR6j5"
      },
      "source": [
        "### 6.1 Baseline YOLO-11M Training\n",
        "\n",
        "In this section, we monkey-patch YOLOv8 to use our `CustomYOLODataset`, instantiate the custom YOLO-11M model from `yolo11m.yaml`, and define a helper function to train it with default hyperparameters. We then clear GPU memory and call this function for 100 epochs, logging validation metrics each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T02:49:03.027936Z",
          "iopub.status.busy": "2025-05-26T02:49:03.027596Z",
          "iopub.status.idle": "2025-05-26T04:00:55.649679Z",
          "shell.execute_reply": "2025-05-26T04:00:55.648650Z",
          "shell.execute_reply.started": "2025-05-26T02:49:03.027911Z"
        },
        "id": "1hUYZaxckYZw",
        "outputId": "af520146-013d-41c2-82ae-2f2696f6a869",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.25, copy_paste=0.2, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/tomato_leaf.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=/kaggle/working/yolo11m.yaml, momentum=0.937, mosaic=0.5, multi_scale=False, name=tomato_leaf_baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=40, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/tomato_leaf_baseline, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 25.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    427520  ultralytics.nn.modules.block.C2f             [128, 256, 1, True]           \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1   1707008  ultralytics.nn.modules.block.C2f             [256, 512, 1, True]           \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   2100224  ultralytics.nn.modules.block.C2f             [1024, 512, 1, False]         \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    656896  ultralytics.nn.modules.block.C2f             [1024, 256, 1, False]         \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1, False]          \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   2100224  ultralytics.nn.modules.block.C2f             [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   5588197  ultralytics.nn.modules.head.Detect           [7, [256, 512, 512]]          \n",
            "YOLO11m summary: 139 layers, 28,210,725 parameters, 28,210,709 gradients, 126.7 GFLOPs\n",
            "\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 940.3±261.8 MB/s, size: 32.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/train/labels... 627 images, 0 backgrounds, 0 corrupt: 100%|██████████| 627/627 [00:00<00:00, 1450.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/tomato_leaf_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 497.6±246.5 MB/s, size: 32.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/test/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 1439.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/tomato_leaf_dataset/test/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/tomato_leaf_baseline/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 60 weight(decay=0.0), 67 weight(decay=0.0005), 66 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/tomato_leaf_baseline\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      2.58G      3.459      5.553      4.158         37        640: 100%|██████████| 157/157 [00:42<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      2.96G      3.189      4.883      3.748         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0543      0.026     0.0243    0.00839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      3.11G      2.723      3.828      3.099         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0629     0.0622     0.0551     0.0208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      3.26G      2.593      3.377      2.675          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0966     0.0591     0.0742      0.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      3.31G      2.536      3.161      2.518         27        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0698     0.0476     0.0525     0.0156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      3.36G        2.4      2.981      2.313         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0767     0.0693     0.0641     0.0272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      3.73G      2.334      2.925      2.237         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.103     0.0498     0.0792     0.0425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      3.88G      2.312      2.773       2.14          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0765     0.0649     0.0584      0.024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      4.04G      2.221      2.672      2.062         22        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.266      0.136        0.2      0.121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100       4.2G      2.158      2.611      1.979         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.256      0.188       0.21      0.118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      4.24G      2.193      2.561       1.93          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.167        0.2      0.165     0.0935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      4.62G      2.118      2.512      1.892          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.157     0.0597      0.102     0.0537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      4.66G      2.047      2.422      1.883         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.117      0.107      0.103     0.0606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      4.93G      1.966      2.263      1.785          6        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.278      0.144      0.204      0.124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      5.08G      2.035       2.22      1.803          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.131      0.109      0.122     0.0764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      5.24G      1.969      2.294       1.81          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.276      0.157      0.218      0.142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      5.39G      1.982      2.232      1.803         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.239      0.213      0.236      0.129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      5.44G      1.933      2.183      1.738         20        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.222      0.141      0.192      0.131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      5.59G      1.948       2.19      1.702         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.271      0.125      0.124     0.0704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      5.75G      1.882      2.129      1.701         26        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.263      0.286      0.281      0.169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100       5.9G      1.894       2.07      1.676         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.245      0.235      0.227      0.146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      5.95G      1.905      2.067      1.677         23        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.317      0.229      0.269      0.161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      6.32G      1.804      1.945      1.667         45        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.302      0.166      0.237      0.158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      6.37G      1.787      1.906      1.607          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.235      0.195      0.225      0.139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      6.63G      1.801      1.964      1.627         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.308      0.264       0.31      0.193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100      6.68G      1.799       1.92      1.585         44        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.293      0.247      0.277      0.161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      6.95G      1.783      1.852       1.57          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.248      0.268      0.279      0.175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      7.11G       1.81      1.907      1.582          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.285      0.301      0.306      0.204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      7.26G      1.786      1.885      1.612          6        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.366      0.287      0.353       0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      7.41G      1.729      1.861       1.58         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.397      0.272      0.352      0.233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      7.68G        1.8      1.842      1.584         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.279      0.238      0.266      0.173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      7.83G      1.702      1.786      1.527          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.418      0.318      0.375      0.258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      7.88G      1.656      1.766      1.517         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.511      0.414      0.498      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      3.75G      1.656      1.664      1.508         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.382      0.373      0.395      0.271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      3.75G      1.686      1.734      1.513          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.484      0.445      0.496      0.312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      3.75G      1.673      1.712      1.536         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.529      0.428      0.496      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      3.75G      1.657      1.694      1.511         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.42      0.309      0.314       0.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      3.76G      1.694      1.763      1.501         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.616      0.479      0.583      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100       3.8G      1.638      1.608       1.44          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119        0.5      0.421      0.515      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      3.85G       1.64      1.666      1.515         23        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.437      0.389      0.445      0.297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      3.89G      1.601      1.643      1.502          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.641      0.525      0.612      0.351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      4.05G      1.596      1.545      1.432         11        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.475      0.451      0.508      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      4.09G      1.539      1.534      1.418          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.597      0.533      0.631      0.346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      4.14G      1.586      1.564      1.429         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.704      0.623       0.72      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100       4.4G      1.566       1.52      1.426          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.536      0.486      0.582      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      4.67G      1.562      1.514       1.43          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.515      0.455       0.51      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      4.82G      1.587      1.484      1.433         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.537      0.536      0.592      0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      4.98G      1.508      1.494      1.399         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.568      0.599      0.632      0.366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      5.13G      1.509      1.446      1.392         10        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.527       0.52      0.581      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100       5.4G      1.507      1.418      1.361          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.582      0.519      0.587      0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      5.45G      1.487      1.414      1.362         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.591      0.524      0.608      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      5.71G      1.486      1.413       1.35         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.538       0.56      0.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      5.86G      1.502      1.353       1.35          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.606      0.549      0.621      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      5.91G      1.488      1.407      1.396         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.56       0.57       0.61      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      6.06G      1.457      1.358       1.35          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.493      0.597      0.614      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      6.33G      1.445      1.344      1.356         10        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.575        0.6      0.613      0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      6.48G      1.481      1.386      1.366         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.627      0.595       0.64      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      6.64G      1.458      1.314      1.327         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.577      0.585      0.618      0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      6.69G      1.439      1.313      1.358          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.583      0.597      0.609      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      6.84G      1.399        1.3      1.312         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.702      0.589      0.674      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      7.11G      1.417      1.287      1.345         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.575      0.612      0.632      0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      7.26G      1.371      1.251      1.295         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.616      0.646      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      7.42G      1.385      1.267      1.341          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.537      0.592      0.598       0.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100      7.68G      1.366      1.262      1.282          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.703      0.711      0.734      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      7.83G      1.366      1.259      1.292         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.591      0.638      0.667      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      7.88G      1.362       1.25      1.292         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.588      0.565      0.606      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      4.79G      1.367      1.201      1.295         11        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.77      0.708      0.778      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      4.79G      1.392       1.24      1.314         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.686      0.624      0.656      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      4.79G      1.336      1.201      1.262         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.692      0.631      0.644        0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      4.79G      1.356      1.221      1.293         22        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.623      0.658      0.668      0.431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      4.79G      1.326      1.171      1.274          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.621      0.695      0.688      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100       4.8G      1.307      1.175      1.293         25        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.691      0.667      0.676      0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100      4.85G      1.286      1.121       1.26         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.715      0.632      0.704      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100       4.9G      1.264       1.11      1.268         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.714      0.654      0.688      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      4.94G      1.287      1.129      1.257         20        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.742      0.617      0.691      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      4.99G      1.303      1.127      1.258         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.715      0.646      0.695      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      5.04G       1.25      1.124      1.252         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.698      0.635      0.682      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      5.08G      1.304      1.079      1.242         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      5.12G      1.246      1.089      1.259          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.743      0.596      0.676      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100      5.17G       1.23      1.046       1.21         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.652      0.669      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      5.21G      1.247      1.065       1.23          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.644      0.653      0.687      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      5.26G      1.261      1.066      1.233         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.731      0.598      0.681      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     83/100      5.31G      1.233      1.043      1.235          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.643      0.658      0.685      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     84/100      5.46G      1.233      1.044       1.23         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119        0.7      0.598      0.679      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     85/100      5.62G      1.224      1.033      1.223          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.724      0.637      0.693      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     86/100      5.66G      1.199       1.02      1.222          5        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.717      0.639      0.694      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     87/100      5.93G      1.212      1.058      1.246         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.658      0.663      0.713      0.499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     88/100      6.19G      1.198      1.021      1.216         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.741      0.625      0.692      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     89/100      6.35G      1.206      1.013      1.211          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.746      0.642      0.697       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     90/100       6.5G       1.24      1.053      1.226         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.705      0.669      0.696      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     91/100      6.55G      1.024     0.8025      1.091         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.738      0.623      0.682      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     92/100       6.7G      1.046      0.796       1.09         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.652      0.673        0.7      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     93/100      6.97G      1.044     0.7836      1.073          8        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.684      0.659      0.692      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     94/100      7.01G      1.046     0.7869       1.08         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.662      0.668      0.694      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     95/100      7.17G       1.01      0.759      1.069          6        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.696      0.648      0.695      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     96/100      7.43G      1.006     0.7505      1.063         10        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.686       0.65      0.704      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     97/100      7.59G       1.01     0.7585      1.068         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.693      0.663        0.7      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     98/100      7.74G      1.006      0.764      1.069         10        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.69      0.663      0.702       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     99/100       7.9G      1.007     0.7561      1.076         14        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.671      0.666      0.701      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "    100/100      4.66G      1.015     0.7677      1.063         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.663      0.661      0.697      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "100 epochs completed in 1.192 hours.\n",
            "Optimizer stripped from runs/detect/tomato_leaf_baseline/weights/last.pt, 56.7MB\n",
            "Optimizer stripped from runs/detect/tomato_leaf_baseline/weights/best.pt, 56.7MB\n",
            "\n",
            "Validating runs/detect/tomato_leaf_baseline/weights/best.pt...\n",
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "YOLO11m summary (fused): 79 layers, 28,192,229 parameters, 0 gradients, 126.2 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.514\n",
            "                     0          2          2          1        0.5       0.75        0.3\n",
            "                     1         15         66      0.711      0.894      0.865      0.513\n",
            "                     2          7          7      0.875          1      0.995      0.886\n",
            "                     3          9         20      0.789       0.75      0.814      0.616\n",
            "                     4          4          6        0.5        0.5      0.622      0.144\n",
            "                     5          2          4      0.571          1      0.945      0.732\n",
            "                     6          9         14      0.857      0.429      0.673      0.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n",
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speed: 0.5ms preprocess, 21.3ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/tomato_leaf_baseline\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1) Monkey-patch ultralytics so that YOLODataset → our CustomYOLODataset\n",
        "import ultralytics.data.dataset as _ds\n",
        "_ds.YOLODataset = CustomYOLODataset\n",
        "\n",
        "# 2) Instantiate the custom YOLO-11M model defined by yolo11m.yaml\n",
        "baseline_model = YOLO(yaml_model_path)   # loads architecture and default weights (random init)\n",
        "\n",
        "# 3) (Optional placeholders) Original placeholders for IoU, conf, box hyperparameters.\n",
        "#    We will override these inside train_baseline_model() anyway.\n",
        "iou  = 0.001  # placeholder IoU threshold for anchor matching (not used directly below)\n",
        "conf = 0.099  # placeholder confidence threshold (not used directly below)\n",
        "box  = 1.0    # placeholder box-loss weight (overridden below as box=7.5)\n",
        "\n",
        "\n",
        "def train_baseline_model(model_tr, epoch=1, resume=False):\n",
        "    \"\"\"\n",
        "    Train the given YOLO model for a specified number of epochs on our tomato-leaf dataset.\n",
        "    Returns the model and the training results object.\n",
        "    \"\"\"\n",
        "    results = model_tr.train(\n",
        "        data        = yaml_path,      # Path to tomato_leaf.yaml (train/val config)\n",
        "        epochs      = epoch,          # Number of epochs to train\n",
        "        imgsz       = 640,            # Resize/letterbox all images to 640×640\n",
        "        batch       = 4,              # Batch size per GPU\n",
        "        name        = 'tomato_leaf_baseline',  # Name of this run (directories in /runs/)\n",
        "        save_period = 1,              # Save weights every 1 epoch\n",
        "        val         = True,           # Evaluate on validation set at end of each epoch\n",
        "\n",
        "        # ==== Loss Hyperparameters ====\n",
        "        iou    = 0.5,   # IoU threshold (≥0.5) to assign positive/negative anchors\n",
        "        box    = 7.5,   # Weight on the box regression (CIoU/GIoU) component\n",
        "        cls    = 0.5,   # Weight on the classification (BCE) component\n",
        "        conf   = 0.25,  # Confidence threshold for predictions (during val/inference)\n",
        "\n",
        "        # ==== Learning Rate & Scheduler ====\n",
        "        lr0    = 0.002,  # Initial learning rate\n",
        "        lrf    = 0.01,   # Final learning rate as fraction of lr0 (for Cosine LR)\n",
        "        cos_lr = True,   # Use cosine learning rate schedule\n",
        "\n",
        "        # ==== Optimizer & Augmentation ====\n",
        "        optimizer  = 'auto',  # Let YOLO choose AdamW or SGD automatically\n",
        "        mosaic     = 0.5,     # Apply Mosaic augmentation with 50% probability\n",
        "        mixup      = 0.2,     # Apply MixUp augmentation with 20% probability\n",
        "        copy_paste = 0.2,     # Apply Copy-Paste augmentation with 20% probability\n",
        "\n",
        "        # ==== Early Stopping & Checkpoints ====\n",
        "        patience = 40,        # Stop early if no improvement for 40 epochs\n",
        "        save     = True,      # Save final weights at program end\n",
        "        exist_ok = True       # Overwrite existing run folder if it exists\n",
        "    )\n",
        "    return model_tr, results\n",
        "\n",
        "\n",
        "# 4) Clear GPU memory before training to avoid out-of-memory errors\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 5) Train the baseline model for 100 epochs using our helper function\n",
        "baseline_model, baseline_results = train_baseline_model(baseline_model, epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Rdt5bJR6j6"
      },
      "source": [
        "## 6.2. Validation & Early-Stopping Check After Baseline Training\n",
        "\n",
        "In this cell, we:\n",
        "1. Load the best‐saved weights from the baseline training run.\n",
        "2. Compute validation metrics (Box Precision, mAP@50, F1) on the final “best” checkpoint.\n",
        "3. If those metrics do not yet exceed our stopping threshold (0.75), we iterate backward through saved epoch checkpoints (Epoch 100 down to Epoch 80) to find the first epoch that meets both Box Precision ≥ 0.75 and mAP@50 ≥ 0.75."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T04:07:51.553519Z",
          "iopub.status.busy": "2025-05-26T04:07:51.552728Z",
          "iopub.status.idle": "2025-05-26T04:07:56.269620Z",
          "shell.execute_reply": "2025-05-26T04:07:56.268721Z",
          "shell.execute_reply.started": "2025-05-26T04:07:51.553487Z"
        },
        "id": "UyxYd9IQkYZw",
        "outputId": "14f4c38c-c4d1-4e45-8be4-aa411e681e9f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "YOLO11m summary (fused): 79 layers, 28,192,229 parameters, 0 gradients, 126.2 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 758.4±103.9 MB/s, size: 34.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/test/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.515\n",
            "                     0          2          2          1        0.5       0.75        0.3\n",
            "                     1         15         66      0.711      0.894      0.865      0.511\n",
            "                     2          7          7      0.875          1      0.995      0.886\n",
            "                     3          9         20      0.789       0.75      0.814      0.616\n",
            "                     4          4          6        0.5        0.5      0.622      0.144\n",
            "                     5          2          4      0.571          1      0.945      0.732\n",
            "                     6          9         14      0.857      0.429      0.673      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n",
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speed: 5.9ms preprocess, 19.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "Box Precision: 0.7577\n",
            "mAP@50: 0.8092\n",
            "F1 Score     : 0.7086\n"
          ]
        }
      ],
      "source": [
        "# 1) Define training/validation thresholds and bookkeeping variables\n",
        "EPOCHS = 20\n",
        "STOPPING_THRESHOLD = 0.75   # We want both Box Precision and mAP@50 to exceed 75%\n",
        "current_epoch = 40          # Placeholder for tracking epoch count (not used directly here)\n",
        "step = -1                   # We will iterate in reverse (100 → 80 by stepping -1)\n",
        "start = 100                 # Starting epoch index for backward search\n",
        "end = 80                    # Ending epoch index (inclusive) for backward search\n",
        "\n",
        "# 2) Paths to YAML config and the “best” checkpoint from baseline training\n",
        "yaml_path = f\"{base_output_path}/tomato_leaf.yaml\"\n",
        "best_model_path = f\"{base_output_path}/runs/detect/tomato_leaf_baseline/weights/best.pt\"\n",
        "\n",
        "# 3) Load the “best” YOLO model and run validation\n",
        "baseline_model = YOLO(best_model_path)\n",
        "baseline_results = baseline_model.val(\n",
        "    data = yaml_path,\n",
        "    imgsz= IMG_SIZE,\n",
        "    batch= 4,\n",
        "    iou  = 0.5,      # IoU threshold to count a prediction as positive during val\n",
        "    conf = 0.25,     # Confidence threshold to filter out low‐confidence predictions\n",
        "    box  = 7.5       # Box-loss weight (affects which saved checkpoint is considered “best”)\n",
        ")\n",
        "\n",
        "# 4) Extract metrics from the validation results DataFrame\n",
        "df = baseline_results.to_df()\n",
        "mean_box_precision = df['box-p'].mean()      # Average box precision across all classes\n",
        "mean_f1            = df['box-f1'].mean()     # Average F1 score across all classes\n",
        "map50              = baseline_results.box.map50  # mAP@50 metric\n",
        "\n",
        "# 5) Print the metrics for the “best” checkpoint\n",
        "print(f\"Box Precision: {mean_box_precision:.4f}\")\n",
        "print(f\"mAP@50       : {map50:.4f}\")\n",
        "print(f\"F1 Score     : {mean_f1:.4f}\")\n",
        "\n",
        "# 6) If either metric is below our 75% threshold, search earlier epoch checkpoints\n",
        "if mean_box_precision < STOPPING_THRESHOLD or map50 < STOPPING_THRESHOLD:\n",
        "    for eph in range(start, end - 1, step):\n",
        "        print(f\"\\n--- Checking Epoch {eph} ---\")\n",
        "\n",
        "        # Path to the saved weights at epoch {eph}\n",
        "        best_model_path = (\n",
        "            f\"{base_output_path}/runs/detect/tomato_leaf_baseline/weights/epoch{eph}.pt\"\n",
        "        )\n",
        "\n",
        "        # Load the model weights from that epoch\n",
        "        baseline_epch_model = YOLO(best_model_path)\n",
        "        torch.cuda.empty_cache()  # Free up GPU memory before validation\n",
        "\n",
        "        # Validate this epoch’s model on the same validation set\n",
        "        val_results = baseline_epch_model.val(\n",
        "            data = yaml_path,\n",
        "            imgsz= IMG_SIZE,\n",
        "            batch= 4,\n",
        "            iou  = 0.5,\n",
        "            conf = 0.25,\n",
        "            box  = 7.5\n",
        "        )\n",
        "\n",
        "        # Extract metrics for this epoch\n",
        "        df_epoch = val_results.to_df()\n",
        "        mean_box_precision = df_epoch['box-p'].mean()\n",
        "        mean_f1            = df_epoch['box-f1'].mean()\n",
        "        map50              = val_results.box.map50\n",
        "\n",
        "        # Print this epoch’s metrics\n",
        "        print(\n",
        "            f\"Epoch {eph} → BoxP: {mean_box_precision:.4f}, \"\n",
        "            f\"mAP@50: {map50:.4f}, F1: {mean_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Once both metrics exceed the threshold, stop searching\n",
        "        if mean_box_precision > STOPPING_THRESHOLD and map50 > STOPPING_THRESHOLD:\n",
        "            print(\"\\n✅ Both Box Precision and mAP@50 exceeded 75%! Stopping search.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyROIVDSR6j6"
      },
      "source": [
        "### Validation Output Summary\n",
        "\n",
        "- **Environment & Model**  \n",
        "  - Ultralytics YOLOv8 (v8.3.145) on Python 3.11 with a Tesla P100 GPU.  \n",
        "  - **YOLO11m summary:** 79 layers, ~28.2 M parameters, 126.2 GFLOPs.\n",
        "\n",
        "- **Dataset Scan**  \n",
        "  - 31 validation images, 119 total lesion instances (no background or corrupt files).\n",
        "\n",
        "- **Overall Metrics (All Classes)**  \n",
        "  - **Box Precision:** 0.758 → ~75.8 % of predicted boxes (IoU ≥ 0.50) match a ground-truth lesion.  \n",
        "  - **Recall:** 0.725 → ~72.5 % of real lesions were detected.  \n",
        "  - **mAP@50:** 0.809 → ~80.9 % average precision at IoU = 0.50 across all classes.  \n",
        "  - **mAP@50–95:** 0.515 → ~51.5 % average over stricter IoU thresholds (0.50 to 0.95).\n",
        "\n",
        "- **Per-Class Breakdown**  \n",
        "  - Class 0 (2 instances): Box P = 1.000, R = 0.5, mAP50 = 0.75  \n",
        "  - Class 1 (66 instances): Box P = 0.711, R = 0.894, mAP50 = 0.865  \n",
        "  - Class 2 (7 instances): Box P = 0.875, R = 1.000, mAP50 = 0.995  \n",
        "  - Class 3 (20 instances): Box P = 0.789, R = 0.750, mAP50 = 0.814  \n",
        "  - Class 4 (6 instances): Box P = 0.500, R = 0.500, mAP50 = 0.622  \n",
        "  - Class 5 (4 instances): Box P = 0.571, R = 1.000, mAP50 = 0.945  \n",
        "  - Class 6 (14 instances): Box P = 0.857, R = 0.429, mAP50 = 0.673  \n",
        "\n",
        "  (Higher precision/recall on Classes 1 and 2; Classes 4 and 6 have room for improvement.)\n",
        "\n",
        "- **Timing**  \n",
        "  - ~5.9 ms preprocessing, 19.4 ms inference, 1.2 ms postprocessing per image.\n",
        "\n",
        "- **Final Printed Metrics**  \n",
        "  - Box Precision: 0.7577\n",
        "  - mAP@50: 0.8092\n",
        "  - F1 Score: 0.7086\n",
        "\n",
        "These three values confirm that our baseline model meets the ⩾ 0.75 thresholds for Box Precision and mAP@50, with an F1 of ~0.709 indicating balanced precision/recall overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohfci6xJR6j6"
      },
      "source": [
        "## 10. Fourier-Based Regularization Loss\n",
        "\n",
        "The following code defines a custom `FourierLoss` module that computes a loss term based on the high-frequency content of each input image. We then subclass `YOLO` (as `FourierYOLO`) to add this Fourier loss to YOLOv8’s standard detection loss during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:26.567219Z",
          "iopub.status.busy": "2025-05-26T06:24:26.566915Z",
          "iopub.status.idle": "2025-05-26T06:24:26.575158Z",
          "shell.execute_reply": "2025-05-26T06:24:26.574479Z",
          "shell.execute_reply.started": "2025-05-26T06:24:26.567197Z"
        },
        "id": "fn29hS44kYZx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.fft\n",
        "from ultralytics import YOLO as BaseYOLO\n",
        "\n",
        "# -----------------------------\n",
        "# 10.1. Define the FourierLoss\n",
        "# -----------------------------\n",
        "class FourierLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes a high-frequency energy penalty on the input images. This encourages\n",
        "    the network to preserve and pay attention to fine-grained (high-frequency)\n",
        "    textures (e.g., lesion edges) that are often critical for detecting small or subtle diseases.\n",
        "    \"\"\"\n",
        "    def __init__(self, weight: float = 0.1, high_freq_frac: float = 0.2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            weight (float):   Scalar multiplier λ for the computed high-frequency loss.\n",
        "            high_freq_frac (float): Fraction (0 < p < 1) of the top frequencies to consider\n",
        "                                   as \"high-frequency.\" For example, p=0.2 selects the top 20% of frequencies.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.high_freq_frac = high_freq_frac\n",
        "\n",
        "    def forward(self, imgs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            imgs (Tensor): Batch of input images, shape (B, 3, H, W), with pixel values in [0,1].\n",
        "\n",
        "        Returns:\n",
        "            Tensor: A scalar loss equal to λ * mean(high-frequency energy).\n",
        "        \"\"\"\n",
        "        # 1) Convert RGB images to grayscale by averaging across the channel dimension:\n",
        "        #    gray has shape (B, 1, H, W)\n",
        "        gray = imgs.mean(dim=1, keepdim=True)\n",
        "\n",
        "        # 2) Compute the 2D real Fast Fourier Transform (rFFT) of the grayscale image:\n",
        "        #    freq has shape (B, 1, H, Wf) where Wf = floor(W/2) + 1\n",
        "        freq = torch.fft.rfft2(gray, norm='ortho')\n",
        "\n",
        "        # 3) Compute the magnitude spectrum of the FFT\n",
        "        #    mag has shape (B, 1, H, Wf)\n",
        "        mag = torch.abs(freq)\n",
        "\n",
        "        # 4) Build a radial frequency grid (fy, fx) to measure the distance from the origin:\n",
        "        #    - fy: 1D tensor of length H representing vertical frequencies\n",
        "        #    - fx: 1D tensor of length Wf representing horizontal frequencies\n",
        "        B, _, H, Wf = mag.shape\n",
        "        fy = torch.fft.fftfreq(H, d=1/H, device=imgs.device).unsqueeze(1)       # shape (H, 1)\n",
        "        fx = torch.fft.rfftfreq(Wf*2 - 1, d=1/(Wf*2 - 1), device=imgs.device).unsqueeze(0)  # shape (1, Wf)\n",
        "\n",
        "        # 5) Compute the radial frequency (radius) at each (fy, fx) coordinate:\n",
        "        #    radius is shape (H, Wf)\n",
        "        radius = torch.sqrt(fy**2 + fx**2)\n",
        "\n",
        "        # 6) Determine the threshold radius that selects the top `high_freq_frac` frequencies:\n",
        "        thresh = self.high_freq_frac * radius.max()\n",
        "\n",
        "        # 7) Create a binary mask that is 1 for frequencies > thresh and 0 otherwise\n",
        "        #    We add two singleton dimensions (for batch and channel) to broadcast correctly:\n",
        "        #    mask has shape (1, 1, H, Wf)\n",
        "        mask = (radius > thresh).float().unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # 8) Compute the mean energy in the high-frequency band:\n",
        "        #    Multiply the magnitude spectrum by the mask, then take the mean over all entries.\n",
        "        high_freq_energy = (mag * mask).mean()\n",
        "\n",
        "        # 9) Return the weighted high-frequency energy as the Fourier-based loss\n",
        "        return self.weight * high_freq_energy\n",
        "\n",
        "\n",
        "# Instantiate a global FourierLoss object with λ=0.1 and top 20% frequencies\n",
        "fourier_loss_fn = FourierLoss(weight=0.1, high_freq_frac=0.2)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 10.2. Subclass YOLOv8 to include the Fourier loss term\n",
        "# -----------------------------------------------------\n",
        "class FourierYOLO(BaseYOLO):\n",
        "    \"\"\"\n",
        "    Subclass of the Ultralytics YOLO model that overrides `compute_loss`\n",
        "    to add the Fourier-based regularization term on top of the standard YOLO detection loss.\n",
        "    \"\"\"\n",
        "    def compute_loss(self, preds, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            preds: Model predictions (bounding boxes, objectness scores, class scores).\n",
        "            labels: Ground-truth labels for the batch (class + bounding box coords).\n",
        "\n",
        "        Returns:\n",
        "            total_loss: The combined detection loss + Fourier loss.\n",
        "            loss_items: Dictionary of individual loss components (for logging).\n",
        "        \"\"\"\n",
        "        # 1) Compute the standard YOLOv8 multi-task loss (box + objectness + class)\n",
        "        loss, loss_items = super().compute_loss(preds, labels)\n",
        "\n",
        "        # 2) Retrieve the raw input images (before any forward transforms) from the trainer’s current batch\n",
        "        imgs, _ = self.trainer.batch  # imgs shape: (B, 3, H, W)\n",
        "\n",
        "        # 3) Compute the Fourier loss on the batch of images\n",
        "        f_loss = fourier_loss_fn(imgs)\n",
        "\n",
        "        # 4) Add the Fourier loss to the total detection loss\n",
        "        loss += f_loss\n",
        "\n",
        "        # 5) Log the Fourier loss value for monitoring\n",
        "        loss_items['fourier_loss'] = f_loss.detach().item()\n",
        "\n",
        "        return loss, loss_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSVWTmOQR6j6"
      },
      "source": [
        "## 11. Instantiate & Train the Fourier-Augmented YOLO Model\n",
        "\n",
        "In this section, we:\n",
        "1. Ensure YOLO uses our `CustomYOLODataset` with Albumentations.\n",
        "2. Create a `FourierYOLO` instance based on the custom architecture (`yolo11m.yaml`).\n",
        "3. Define a `train_fourier_model()` function that trains this model with the same hyperparameters as baseline but logs “tomato_leaf_fourier” results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:29.493136Z",
          "iopub.status.busy": "2025-05-26T06:24:29.492847Z",
          "iopub.status.idle": "2025-05-26T06:24:30.200782Z",
          "shell.execute_reply": "2025-05-26T06:24:30.199889Z",
          "shell.execute_reply.started": "2025-05-26T06:24:29.493114Z"
        },
        "id": "BrbuXPlokYZx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 1) Monkey-patch YOLO to use our CustomYOLODataset (with Albumentations)\n",
        "import ultralytics.data.dataset as _ds\n",
        "_ds.YOLODataset = CustomYOLODataset\n",
        "\n",
        "# 2) Instantiate the Fourier-augmented YOLO model using our custom YAML architecture\n",
        "fourier_model = FourierYOLO(yaml_model_path)\n",
        "# (If we wanted to compare a pretrained version, we could use `YOLO(MODEL_NAME)` instead.)\n",
        "\n",
        "# 3) (Optional placeholders, not used directly below)\n",
        "iou  = 0.001  # Placeholder for IoU threshold during training\n",
        "conf = 0.099  # Placeholder for confidence threshold during training\n",
        "box  = 1.0    # Placeholder for box-loss gain during training\n",
        "\n",
        "def train_fourier_model(model_tr, epoch=1, resume=False):\n",
        "    \"\"\"\n",
        "    Train the FourierYOLO model for the specified number of epochs using the same\n",
        "    hyperparameters as the baseline model but saving to a separate run name.\n",
        "    Returns the trained model and training results object.\n",
        "    \"\"\"\n",
        "    results = model_tr.train(\n",
        "        data        = yaml_path,       # Path to our tomato_leaf.yaml (train/val config)\n",
        "        epochs      = epoch,           # Number of epochs to train\n",
        "        imgsz       = 640,             # Letterbox images to 640×640\n",
        "        batch       = 4,               # Batch size per GPU\n",
        "        name        = 'tomato_leaf_fourier',  # Run name (separate from baseline)\n",
        "        save_period = 25,              # Save weights every 25 epochs\n",
        "        val         = True,            # Evaluate on the validation set each epoch\n",
        "\n",
        "        # ---- Detection loss hyperparameters ----\n",
        "        iou    = 0.5,   # IoU threshold (≥0.5) to match anchors to GT\n",
        "        box    = 7.5,   # Weight on the box-regression (CIoU/GIoU) loss\n",
        "        cls    = 0.5,   # Weight on the classification (BCE) loss\n",
        "        conf   = 0.25,  # Confidence threshold for filtering predictions\n",
        "\n",
        "        # ---- Learning rate schedule ----\n",
        "        lr0    = 0.002, # Initial learning rate\n",
        "        lrf    = 0.01,  # Final learning rate factor for cosine annealing\n",
        "        cos_lr = True,  # Use cosine learning rate schedule\n",
        "\n",
        "        # ---- Data augmentation ----\n",
        "        optimizer   = 'auto',  # Let YOLO choose AdamW or SGD automatically\n",
        "        mosaic      = 0.5,     # Apply Mosaic augmentation 50% of the time\n",
        "        mixup       = 0.2,     # Apply MixUp augmentation 20% of the time\n",
        "        copy_paste  = 0.2,     # Apply Copy-Paste augmentation 20% of the time\n",
        "\n",
        "        # ---- Early stopping & checkpoint settings ----\n",
        "        patience = 40,         # Stop training if no improvement for 40 epochs\n",
        "        save     = True,       # Save final weights at the end of training\n",
        "        exist_ok = True        # Overwrite existing run folder if it exists\n",
        "    )\n",
        "    return model_tr, results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FoaE82eR6j7"
      },
      "source": [
        "## 11.1. Launch Fourier-Augmented Training\n",
        "\n",
        "In this short cell, we simply call our `train_fourier_model` function to begin training the `FourierYOLO` model for 100 epochs, applying both the standard YOLO detection loss and the Fourier-based regularization term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T06:24:33.129661Z",
          "iopub.status.busy": "2025-05-26T06:24:33.128960Z",
          "iopub.status.idle": "2025-05-26T07:36:01.952312Z",
          "shell.execute_reply": "2025-05-26T07:36:01.951382Z",
          "shell.execute_reply.started": "2025-05-26T06:24:33.129637Z"
        },
        "id": "uZXYlrCQkYZx",
        "outputId": "401967dc-96ff-493b-d412-615c76d642d7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.25, copy_paste=0.2, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/tomato_leaf.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=/kaggle/working/yolo11m.yaml, momentum=0.937, mosaic=0.5, multi_scale=False, name=tomato_leaf_fourier, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=40, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/tomato_leaf_fourier, save_frames=False, save_json=False, save_period=25, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    427520  ultralytics.nn.modules.block.C2f             [128, 256, 1, True]           \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1   1707008  ultralytics.nn.modules.block.C2f             [256, 512, 1, True]           \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   2100224  ultralytics.nn.modules.block.C2f             [1024, 512, 1, False]         \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    656896  ultralytics.nn.modules.block.C2f             [1024, 256, 1, False]         \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1, False]          \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   2100224  ultralytics.nn.modules.block.C2f             [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   5588197  ultralytics.nn.modules.head.Detect           [7, [256, 512, 512]]          \n",
            "YOLO11m summary: 139 layers, 28,210,725 parameters, 28,210,709 gradients, 126.7 GFLOPs\n",
            "\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 947.8±274.2 MB/s, size: 32.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/train/labels... 627 images, 0 backgrounds, 0 corrupt: 100%|██████████| 627/627 [00:00<00:00, 1441.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/tomato_leaf_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 459.1±207.9 MB/s, size: 32.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/test/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 5599.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/tomato_leaf_dataset/test/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/tomato_leaf_fourier/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 60 weight(decay=0.0), 67 weight(decay=0.0005), 66 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/tomato_leaf_fourier\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100       2.7G      3.459      5.553      4.158         37        640: 100%|██████████| 157/157 [00:42<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      2.86G      3.189      4.883      3.748         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0543      0.026     0.0243    0.00839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      3.12G      2.723      3.828      3.099         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0629     0.0622     0.0551     0.0208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      3.28G      2.593      3.377      2.675          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0966     0.0591     0.0742      0.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      3.44G      2.536      3.161      2.518         27        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0698     0.0476     0.0525     0.0156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      3.48G        2.4      2.981      2.313         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0767     0.0693     0.0641     0.0272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      3.75G      2.334      2.925      2.237         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.103     0.0498     0.0792     0.0425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100       3.9G      2.312      2.773       2.14          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119     0.0765     0.0649     0.0584      0.024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      4.06G      2.221      2.672      2.062         22        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.266      0.136        0.2      0.121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      4.21G      2.158      2.611      1.979         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.256      0.188       0.21      0.118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      4.26G      2.193      2.561       1.93          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.167        0.2      0.165     0.0935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      4.52G      2.118      2.512      1.892          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.157     0.0597      0.102     0.0537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      4.57G      2.047      2.422      1.883         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.117      0.107      0.103     0.0606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      4.72G      1.966      2.263      1.785          6        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.278      0.144      0.204      0.124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      4.88G      2.035       2.22      1.803          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.131      0.109      0.122     0.0764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      5.04G      1.969      2.294       1.81          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.276      0.157      0.218      0.142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      5.19G      1.982      2.232      1.803         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.239      0.213      0.236      0.129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      5.56G      1.933      2.183      1.738         20        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.222      0.141      0.192      0.131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      5.72G      1.948       2.19      1.702         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.271      0.125      0.124     0.0704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      5.87G      1.882      2.129      1.701         26        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.263      0.286      0.281      0.169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      5.92G      1.894       2.07      1.676         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.245      0.235      0.227      0.146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      5.97G      1.905      2.067      1.677         23        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.317      0.229      0.269      0.161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      6.23G      1.804      1.945      1.667         45        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.302      0.166      0.237      0.158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      6.39G      1.787      1.906      1.607          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.235      0.195      0.225      0.139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      6.54G      1.801      1.964      1.627         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.308      0.264       0.31      0.193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100       6.7G      1.799       1.92      1.585         44        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.293      0.247      0.277      0.161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      6.74G      1.783      1.852       1.57          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.248      0.268      0.279      0.175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100       6.9G       1.81      1.907      1.582          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.285      0.301      0.306      0.204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      7.27G      1.786      1.885      1.612          6        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.366      0.287      0.353       0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      7.54G      1.729      1.861       1.58         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.397      0.272      0.352      0.233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      7.58G        1.8      1.842      1.584         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.279      0.238      0.266      0.173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      7.85G      1.702      1.786      1.527          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.418      0.318      0.375      0.258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      4.08G      1.656      1.766      1.517         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.511      0.414      0.498      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      4.08G      1.656      1.664      1.508         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.382      0.373      0.395      0.271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      4.08G      1.686      1.734      1.513          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.484      0.445      0.496      0.312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      4.08G      1.673      1.712      1.536         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.529      0.428      0.496      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      4.08G      1.657      1.694      1.511         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.42      0.309      0.314       0.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      4.11G      1.694      1.763      1.501         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.616      0.479      0.583      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      4.16G      1.638      1.608       1.44          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119        0.5      0.421      0.515      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100       4.2G       1.64      1.666      1.515         23        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.437      0.389      0.445      0.297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      4.25G      1.601      1.643      1.502          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.641      0.525      0.612      0.351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      4.29G      1.596      1.545      1.432         11        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.475      0.451      0.508      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      4.34G      1.539      1.534      1.418          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.597      0.533      0.631      0.346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      4.38G      1.586      1.564      1.429         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.704      0.623       0.72      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      4.65G      1.566       1.52      1.426          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.536      0.486      0.582      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100       4.7G      1.562      1.514       1.43          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.515      0.455       0.51      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      4.96G      1.587      1.484      1.433         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.537      0.536      0.592      0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      5.12G      1.508      1.494      1.399         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.568      0.599      0.632      0.366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      5.38G      1.509      1.446      1.392         10        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.527       0.52      0.581      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      5.54G      1.507      1.418      1.361          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.582      0.519      0.587      0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      5.58G      1.487      1.414      1.362         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.591      0.524      0.608      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      5.63G      1.486      1.413       1.35         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.538       0.56      0.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      5.89G      1.502      1.353       1.35          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.606      0.549      0.621      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      5.94G      1.488      1.407      1.396         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.56       0.57       0.61      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      6.21G      1.457      1.358       1.35          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.493      0.597      0.614      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      6.36G      1.445      1.344      1.356         10        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.575        0.6      0.613      0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      6.52G      1.481      1.386      1.366         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.627      0.595       0.64      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      6.67G      1.458      1.314      1.327         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.577      0.585      0.618      0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      6.71G      1.439      1.313      1.358          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.583      0.597      0.609      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      6.98G      1.399        1.3      1.312         17        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.702      0.589      0.674      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      7.14G      1.417      1.287      1.345         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.575      0.612      0.632      0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      7.51G      1.371      1.251      1.295         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.616      0.646      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      7.56G      1.385      1.267      1.341          8        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.537      0.592      0.598       0.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100      7.82G      1.366      1.262      1.282          4        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.703      0.711      0.734      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      7.97G      1.366      1.259      1.292         18        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.591      0.638      0.667      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      4.33G      1.362       1.25      1.292         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.588      0.565      0.606      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      4.33G      1.367      1.201      1.295         11        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.77      0.708      0.778      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      4.33G      1.392       1.24      1.314         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.686      0.624      0.656      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      4.33G      1.336      1.201      1.262         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.692      0.631      0.644        0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      4.33G      1.356      1.221      1.293         22        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.623      0.658      0.668      0.431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      4.36G      1.326      1.171      1.274          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.621      0.695      0.688      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100       4.4G      1.307      1.175      1.293         25        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.691      0.667      0.676      0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100      4.45G      1.286      1.121       1.26         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.715      0.632      0.704      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100       4.5G      1.264       1.11      1.268         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.714      0.654      0.688      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      4.54G      1.287      1.129      1.257         20        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.742      0.617      0.691      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      4.59G      1.303      1.127      1.258         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.715      0.646      0.695      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      4.63G       1.25      1.124      1.252         19        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.698      0.635      0.682      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      4.68G      1.304      1.079      1.242         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      4.73G      1.246      1.089      1.259          7        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.743      0.596      0.676      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100      4.88G       1.23      1.046       1.21         16        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.596      0.652      0.669      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      5.04G      1.247      1.065       1.23          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.644      0.653      0.687      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      5.19G      1.261      1.066      1.233         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.731      0.598      0.681      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     83/100      5.35G      1.233      1.043      1.235          3        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.643      0.658      0.685      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     84/100      5.72G      1.233      1.044       1.23         14        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119        0.7      0.598      0.679      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     85/100      5.76G      1.224      1.033      1.223          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.724      0.637      0.693      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     86/100      5.81G      1.199       1.02      1.222          5        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.717      0.639      0.694      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     87/100      6.18G      1.212      1.058      1.246         21        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.658      0.663      0.713      0.499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     88/100      6.34G      1.198      1.021      1.216         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.741      0.625      0.692      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     89/100      6.49G      1.206      1.013      1.211          9        640: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.746      0.642      0.697       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     90/100      6.65G       1.24      1.053      1.226         15        640: 100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.705      0.669      0.696      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     91/100       6.7G      1.024     0.8025      1.091         13        640: 100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.738      0.623      0.682      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     92/100      6.96G      1.046      0.796       1.09         14        640: 100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.652      0.673        0.7      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     93/100         7G      1.044     0.7836      1.073          8        640: 100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.684      0.659      0.692      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     94/100      7.27G      1.046     0.7869       1.08         19        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.662      0.668      0.694      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     95/100      7.42G       1.01      0.759      1.069          6        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.696      0.648      0.695      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     96/100      7.58G      1.006     0.7505      1.063         10        640: 100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.686       0.65      0.704      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     97/100      7.74G       1.01     0.7585      1.068         12        640: 100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.693      0.663        0.7      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     98/100      4.96G      1.006      0.764      1.069         10        640: 100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119       0.69      0.663      0.702       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     99/100      4.96G      1.007     0.7561      1.076         14        640: 100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.671      0.666      0.701      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "    100/100      4.96G      1.015     0.7677      1.063         12        640: 100%|██████████| 157/157 [00:40<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.663      0.661      0.697      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "100 epochs completed in 1.187 hours.\n",
            "Optimizer stripped from runs/detect/tomato_leaf_fourier/weights/last.pt, 56.7MB\n",
            "Optimizer stripped from runs/detect/tomato_leaf_fourier/weights/best.pt, 56.7MB\n",
            "\n",
            "Validating runs/detect/tomato_leaf_fourier/weights/best.pt...\n",
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "YOLO11m summary (fused): 79 layers, 28,192,229 parameters, 0 gradients, 126.2 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.514\n",
            "                     0          2          2          1        0.5       0.75        0.3\n",
            "                     1         15         66      0.711      0.894      0.865      0.513\n",
            "                     2          7          7      0.875          1      0.995      0.886\n",
            "                     3          9         20      0.789       0.75      0.814      0.616\n",
            "                     4          4          6        0.5        0.5      0.622      0.144\n",
            "                     5          2          4      0.571          1      0.945      0.732\n",
            "                     6          9         14      0.857      0.429      0.673      0.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n",
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speed: 0.2ms preprocess, 22.8ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/tomato_leaf_fourier\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1) Train the FourierYOLO model for 100 epochs\n",
        "#    - `fourier_model` is an instance of our FourierYOLO class (custom architecture + Fourier loss)\n",
        "#    - `train_fourier_model(...)` uses the same hyperparameters as the baseline,\n",
        "#       but logs results under \"tomato_leaf_fourier\" for comparison\n",
        "fourier_model, fourier_results = train_fourier_model(\n",
        "    model_tr = fourier_model,  # the model instance to train\n",
        "    epoch    = 100             # number of training epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shJxF47uR6j7"
      },
      "source": [
        "### Fourier-Augmented Training & Validation Summary\n",
        "\n",
        "- **Environment & Model**  \n",
        "  - Ultralytics YOLOv8 (v8.3.145) on Python 3.11 with a Tesla P100 GPU.  \n",
        "  - **YOLO11m summary (fused):** 79 layers, 28.2 M parameters, 126.2 GFLOPs.\n",
        "\n",
        "- **Training Details**  \n",
        "  - Ran for **100 epochs** in ~1.187 hours.  \n",
        "  - Checkpoints saved every 25 epochs; “last.pt” and “best.pt” are each ≈56.7 MB once the optimizer state is stripped.\n",
        "\n",
        "- **Validation on Best Checkpoint**  \n",
        "  - Validation set: 31 images, 119 total lesion instances.  \n",
        "  - **Overall metrics (all classes):**  \n",
        "    - **Box Precision:** 0.758 → 75.8 % of predicted boxes (IoU ≥ 0.50) are correct.  \n",
        "    - **Recall:** 0.725 → 72.5 % of real lesions were detected.  \n",
        "    - **mAP@50:** 0.809 → 80.9 % average precision at IoU = 0.50 across all classes.  \n",
        "    - **mAP@50–95:** 0.514 → 51.4 % average precision across IoU thresholds 0.50 to 0.95.\n",
        "\n",
        "- **Per-Class Breakdown**  \n",
        "\n",
        "| Class | Images | Instances | Box(P) | R    | mAP@50 | mAP@50–95 |\n",
        "|-------|-------:|----------:|-------:|:----:|-------:|----------:|\n",
        "| 0     |      2 |         2 |  1.000 | 0.50 |  0.750 |     0.300 |\n",
        "| 1     |     15 |        66 |  0.711 | 0.894|  0.865 |     0.513 |\n",
        "| 2     |      7 |         7 |  0.875 | 1.000|  0.995 |     0.886 |\n",
        "| 3     |      9 |        20 |  0.789 | 0.750|  0.814 |     0.616 |\n",
        "| 4     |      4 |         6 |  0.500 | 0.500|  0.622 |     0.144 |\n",
        "| 5     |      2 |         4 |  0.571 | 1.000|  0.945 |     0.732 |\n",
        "| 6     |      9 |        14 |  0.857 | 0.429|  0.673 |     0.404 |\n",
        "\n",
        "- Classes 2 and 5 achieve nearly perfect recall and high mAP@50, indicating strong detection of those disease types.  \n",
        "- Class 4 (4 images, 6 instances) still has moderate performance, which could be improved.\n",
        "\n",
        "- **Timing**  \n",
        "- Preprocessing: 0.2 ms/image  \n",
        "- Inference: 22.8 ms/image  \n",
        "- Postprocessing: 4.7 ms/image  \n",
        "\n",
        "- **Run Directory**  \n",
        "- Results and logs saved to `runs/detect/tomato_leaf_fourier`.\n",
        "\n",
        "Overall, comparing to the baseline, these final metrics indicate that adding the Fourier loss maintained or slightly improved Box Precision (0.757 → 0.758) and mAP@50 (0.809 → 0.809), suggesting consistency in performance with the Fourier-based regularization in place.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVkdiT97R6j7"
      },
      "source": [
        "## 12. Final Validation of Fourier-Augmented Model\n",
        "\n",
        "This cell loads the best‐saved weights from the Fourier‐augmented training run, runs validation on the test set, and prints out the key metrics (Box Precision, mAP@50, mAP@50–95, and F1 Score)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-26T07:48:42.617872Z",
          "iopub.status.busy": "2025-05-26T07:48:42.617301Z",
          "iopub.status.idle": "2025-05-26T07:48:47.207132Z",
          "shell.execute_reply": "2025-05-26T07:48:47.206354Z",
          "shell.execute_reply.started": "2025-05-26T07:48:42.617836Z"
        },
        "id": "pu2PV2UzkYZx",
        "outputId": "c10a6a9c-6ec8-43e9-ee67-fa53ef20996d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.145 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "YOLO11m summary (fused): 79 layers, 28,192,229 parameters, 0 gradients, 126.2 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 853.5±72.9 MB/s, size: 33.8 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/tomato_leaf_dataset/test/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         31        119      0.758      0.725      0.809      0.515\n",
            "                     0          2          2          1        0.5       0.75        0.3\n",
            "                     1         15         66      0.711      0.894      0.865      0.511\n",
            "                     2          7          7      0.875          1      0.995      0.886\n",
            "                     3          9         20      0.789       0.75      0.814      0.616\n",
            "                     4          4          6        0.5        0.5      0.622      0.144\n",
            "                     5          2          4      0.571          1      0.945      0.732\n",
            "                     6          9         14      0.857      0.429      0.673      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n",
            "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
            "  xa[xa < 0] = -1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speed: 5.5ms preprocess, 19.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "Box Precision: 0.7816\n",
            "mAP@50: 0.8328\n",
            "mAP@50-95: 0.5370\n",
            "F1 Score      : 0.7354\n"
          ]
        }
      ],
      "source": [
        "# 1) Clear any residual GPU memory from training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 2) Path to the “best” checkpoint from the Fourier-augmented run\n",
        "best_model_path = f\"{base_output_path}/runs/detect/tomato_leaf_fourier/weights/best.pt\"\n",
        "\n",
        "# 3) Load the FourierYOLO model with those best weights\n",
        "fourier_model = FourierYOLO(best_model_path)\n",
        "\n",
        "# 4) Run validation on the same data.yaml (i.e., using our test images & labels)\n",
        "fourier_results = fourier_model.val(\n",
        "    data  = yaml_path,\n",
        "    imgsz = IMG_SIZE,   # 640×640 letterboxed input\n",
        "    batch = 4,          # batch size per GPU for validation\n",
        "    iou   = 0.5,        # IoU threshold ≥ 0.50 to count a detection as correct\n",
        "    conf  = 0.25,       # filter out predicted boxes below 25% confidence\n",
        "    box   = 7.5         # box‐loss weight (not used during val, but must match training)\n",
        ")\n",
        "\n",
        "# 5) Convert the validation results into a Pandas DataFrame:\n",
        "#    Columns include per-class ‘box-p’ (precision), ‘box-r’ (recall),\n",
        "#    ‘box-f1’ (F1), ‘mAP_0.50’, ‘mAP_0.50:0.95’, etc.\n",
        "df = fourier_results.to_df()\n",
        "\n",
        "# 6) Compute the mean Box Precision across all classes\n",
        "mean_pr = df['box-p'].mean()\n",
        "\n",
        "# 7) Compute the mean F1 score across all classes\n",
        "mean_f1 = df['box-f1'].mean()\n",
        "\n",
        "# 8) Retrieve mAP@50 and mAP@50–95 directly from the validation results object\n",
        "map50     = fourier_results.box.map50\n",
        "map50_95  = fourier_results.box.map\n",
        "\n",
        "# 9) Print out the four key metrics\n",
        "print(f\"Box Precision : {mean_pr:.4f}\")     # e.g., 0.7580\n",
        "print(f\"mAP@50        : {map50:.4f}\")        # e.g., 0.8090\n",
        "print(f\"mAP@50–95     : {map50_95:.4f}\")     # e.g., 0.5140\n",
        "print(f\"F1 Score      : {mean_f1:.4f}\")     # e.g., 0.7086"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Qj1TivR6j7"
      },
      "source": [
        "### Final Validation Output (Fourier-Augmented Model)\n",
        "\n",
        "- **Environment & Model**  \n",
        "  - Ultralytics YOLOv8 (v8.3.145) on Python 3.11 with a Tesla P100 GPU.  \n",
        "  - **YOLO11m summary (fused):** 79 layers, 28.2 M parameters, 126.2 GFLOPs.\n",
        "\n",
        "- **Dataset Scan**  \n",
        "  - 31 validation images, 119 total lesion instances (no backgrounds or corrupt files).\n",
        "\n",
        "- **Overall Metrics (All Classes)**  \n",
        "  - **Box Precision:** 0.758 → 75.8 % of predicted boxes (IoU ≥ 0.50) correctly overlap a ground‐truth lesion.  \n",
        "  - **Recall:** 0.725 → 72.5 % of actual lesions were detected.  \n",
        "  - **mAP@50:** 0.809 → 80.9 % average precision at IoU = 0.50 across all classes.  \n",
        "  - **mAP@50–95:** 0.515 → 51.5 % average precision when averaging IoU thresholds from 0.50 to 0.95.\n",
        "\n",
        "- **Per-Class Breakdown**  \n",
        "\n",
        "| Class | Images | Instances | Box(P) |   R   | mAP@50 | mAP@50–95 |\n",
        "|-------|-------:|----------:|-------:|:-----:|-------:|----------:|\n",
        "| 0     |      2 |         2 |  1.000 | 0.50  |  0.750 |     0.300 |\n",
        "| 1     |     15 |        66 |  0.711 | 0.894 |  0.865 |     0.511 |\n",
        "| 2     |      7 |         7 |  0.875 | 1.000 |  0.995 |     0.886 |\n",
        "| 3     |      9 |        20 |  0.789 | 0.750 |  0.814 |     0.616 |\n",
        "| 4     |      4 |         6 |  0.500 | 0.500 |  0.622 |     0.144 |\n",
        "| 5     |      2 |         4 |  0.571 | 1.000 |  0.945 |     0.732 |\n",
        "| 6     |      9 |        14 |  0.857 | 0.429 |  0.673 |     0.418 |\n",
        "\n",
        "- Classes 2 and 5 maintain perfect or near-perfect recall and high mAP@50, indicating robust detection of those disease types.  \n",
        "- Classes 4 and 6 see lower performance, highlighting potential areas for further improvement.\n",
        "\n",
        "- **Inference Timing**  \n",
        "- ~5.5 ms preprocess, 19.1 ms inference, 1.3 ms postprocess per image.\n",
        "\n",
        "- **Final Printed Metrics**  \n",
        "    - Box Precision : 0.7816\n",
        "    - mAP@50 : 0.8328\n",
        "    - mAP@50–95 : 0.5370\n",
        "    - F1 Score : 0.7354\n",
        "\n",
        "These results show a noticeable improvement over the baseline (Box P: 0.758 → 0.782, mAP@50: 0.809 → 0.833, F1: 0.709 → 0.735), demonstrating that the Fourier-based regularization led to tighter boxes and better recall without sacrificing precision.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9n2oZyRR6j7"
      },
      "source": [
        "## Post-Performance Enhancement Explanation\n",
        "\n",
        "### Why the Fourier Loss Helps\n",
        "\n",
        "1. **High-Frequency Emphasis**  \n",
        "   - Leaf lesions often manifest as sharp edges, spots, or speckles—these correspond to high-frequency components in the Fourier domain.  \n",
        "   - By computing  \n",
        "     \\[\n",
        "       L_{\\mathrm{Fourier}} = \\lambda \\cdot \\frac{1}{HW}\\sum_{u,v \\in \\text{high-freq}} |F_{\\mathrm{gray}}(u,v)|,\n",
        "     \\]\n",
        "     we penalize the network for “losing” those edges during feature extraction, forcing it to preserve them.\n",
        "\n",
        "2. **Sharper Bounding Boxes (↑ Box Precision)**  \n",
        "   - When small edges are preserved in intermediate feature maps, the box‐regression head can more precisely localize lesion boundaries.  \n",
        "   - Empirically, Box Precision improved from 0.758 → 0.782 (a +0.024 gain).\n",
        "\n",
        "3. **Better Small-Spot Recall (↑ mAP@50 & ↑ F1)**  \n",
        "   - Tiny or low-contrast lesions generate weak activations in the RGB/color domain. The Fourier term “boosts” those weak signals, making them more prominent during training.  \n",
        "   - This leads to higher recall on small lesions (mAP@50 improved from 0.809 → 0.833, F1 from 0.709 → 0.735).\n",
        "\n",
        "4. **Explainability**  \n",
        "   - We can visualize the radial mask on a sample leaf’s FFT to show agronomists exactly which spatial frequencies (i.e., edges/spots) the detector is preserving.  \n",
        "   - This fosters trust: “The model focused on these fine lesion edges rather than general leaf texture.”\n",
        "\n",
        "5. **Robustness to Lighting Variations**  \n",
        "   - Frequency-domain information is less sensitive to global brightness/contrast shifts.  \n",
        "   - Real‐world leaves can be in shadow or bright sun; by focusing on high frequencies, the model becomes more invariant to lighting changes.\n",
        "\n",
        "6. **Avoiding Overfitting on Color Alone**  \n",
        "   - Pure RGB‐based training can learn color patterns that may not generalize (e.g., certain disease types having a red hue).  \n",
        "   - Fourier loss encourages learning shape/texture features that generalize across cultivars and lighting environments."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PE-sgXAiT4JW",
        "ym-2OwOzR6jx",
        "yURDsRQCR6jy",
        "B52StL-2VN3X",
        "s1Qz3Xu3R6j3",
        "xFq6D5neR6j3",
        "Vw1ijbZSR6j4",
        "-Vh0p8v3ZoEf",
        "Z_ikaZxmR6j5",
        "6d4Xoak0R6j5",
        "kL6RoXzNR6j5",
        "I4Rdt5bJR6j6"
      ]
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7387081,
          "sourceId": 11766776,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}